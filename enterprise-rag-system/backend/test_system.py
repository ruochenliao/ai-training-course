#!/usr/bin/env python3
"""
ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.services.agent_service import (
    QueryContext,
    query_analyzer
)
from app.services.workflow_service import (
    workflow_orchestrator,
    WorkflowConfig,
    WorkflowType
)
from app.services.llm_service import LLMService
from app.services.embedding_service import embedding_service
from app.services.vector_db import VectorDBService
from app.services.graph_db_service import neo4j_service


async def test_llm_service():
    """æµ‹è¯•LLMæœåŠ¡"""
    print("ğŸ§  æµ‹è¯•LLMæœåŠ¡...")
    
    try:
        llm = LLMService()
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await llm.check_model_health()
        print(f"LLMå¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
        response = await llm.generate_text(
            prompt="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
            max_tokens=100
        )
        print(f"LLMå“åº”: {response[:100]}...")
        
        print("âœ… LLMæœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_embedding_service():
    """æµ‹è¯•åµŒå…¥æœåŠ¡"""
    print("ğŸ”¢ æµ‹è¯•åµŒå…¥æœåŠ¡...")
    
    try:
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await embedding_service.health_check()
        print(f"åµŒå…¥æœåŠ¡å¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬åµŒå…¥
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        embedding = await embedding_service.create_embeddings(text)
        print(f"åµŒå…¥å‘é‡ç»´åº¦: {len(embedding)}")
        
        # æµ‹è¯•æ‰¹é‡åµŒå…¥
        texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
        embeddings = await embedding_service.create_embeddings(texts)
        print(f"æ‰¹é‡åµŒå…¥ç»“æœ: {len(embeddings)} ä¸ªå‘é‡")
        
        print("âœ… åµŒå…¥æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ åµŒå…¥æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_vector_db():
    """æµ‹è¯•å‘é‡æ•°æ®åº“"""
    print("ğŸ—„ï¸ æµ‹è¯•å‘é‡æ•°æ®åº“...")
    
    try:
        vector_db = VectorDBService()
        
        # æµ‹è¯•è¿æ¥
        await vector_db.connect()
        print("å‘é‡æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await vector_db.health_check()
        print(f"å‘é‡æ•°æ®åº“å¥åº·çŠ¶æ€: {health}")
        
        print("âœ… å‘é‡æ•°æ®åº“æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å‘é‡æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_graph_db():
    """æµ‹è¯•å›¾æ•°æ®åº“"""
    print("ğŸ•¸ï¸ æµ‹è¯•å›¾æ•°æ®åº“...")
    
    try:
        # æµ‹è¯•è¿æ¥
        await neo4j_service.connect()
        print("å›¾æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await neo4j_service.health_check()
        print(f"å›¾æ•°æ®åº“å¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•ç®€å•æŸ¥è¯¢
        result = await neo4j_service.execute_query("RETURN 1 as test")
        print(f"æµ‹è¯•æŸ¥è¯¢ç»“æœ: {result}")
        
        print("âœ… å›¾æ•°æ®åº“æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å›¾æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_agents():
    """æµ‹è¯•æ™ºèƒ½ä½“"""
    print("ğŸ¤– æµ‹è¯•æ™ºèƒ½ä½“ç³»ç»Ÿ...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = QueryContext(
            query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            user_id=1,
            knowledge_base_ids=[1],
            metadata={"test": True}
        )
        
        # æµ‹è¯•æŸ¥è¯¢åˆ†ææ™ºèƒ½ä½“
        print("æµ‹è¯•æŸ¥è¯¢åˆ†ææ™ºèƒ½ä½“...")
        analysis_result = await query_analyzer.process(context)
        print(f"æŸ¥è¯¢åˆ†æç»“æœ: {analysis_result}")
        
        print("âœ… æ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_workflow():
    """æµ‹è¯•å·¥ä½œæµ"""
    print("âš™ï¸ æµ‹è¯•å·¥ä½œæµç³»ç»Ÿ...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = QueryContext(
            query="è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
            user_id=1,
            knowledge_base_ids=[1],
            metadata={"test": True}
        )
        
        # é…ç½®å·¥ä½œæµ
        config = WorkflowConfig(
            workflow_type=WorkflowType.SIMPLE_QA,
            enable_vector_search=False,  # æš‚æ—¶ç¦ç”¨ï¼Œé¿å…æ•°æ®åº“ä¾èµ–
            enable_graph_search=False,
            enable_result_fusion=False
        )
        
        # æ‰§è¡Œå·¥ä½œæµ
        print("æ‰§è¡Œæµ‹è¯•å·¥ä½œæµ...")
        result = await workflow_orchestrator.execute_workflow(context, config)
        print(f"å·¥ä½œæµç»“æœ: {result.answer[:100]}...")
        print(f"å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
        print(f"ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
        
        print("âœ… å·¥ä½œæµç³»ç»Ÿæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_stream_workflow():
    """æµ‹è¯•æµå¼å·¥ä½œæµ"""
    print("ğŸŒŠ æµ‹è¯•æµå¼å·¥ä½œæµ...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = QueryContext(
            query="è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ ",
            user_id=1,
            knowledge_base_ids=[1],
            metadata={"test": True}
        )
        
        # é…ç½®å·¥ä½œæµ
        config = WorkflowConfig(
            workflow_type=WorkflowType.SIMPLE_QA,
            enable_vector_search=False,
            enable_graph_search=False,
            enable_result_fusion=False
        )
        
        # æ‰§è¡Œæµå¼å·¥ä½œæµ
        print("æ‰§è¡Œæµå¼å·¥ä½œæµ...")
        answer_chunks = []
        
        async for event in workflow_orchestrator.execute_workflow_stream(context, config):
            if event["type"] == "answer_chunk":
                chunk = event["data"]["chunk"]
                answer_chunks.append(chunk)
                print(chunk, end="", flush=True)
            elif event["type"] == "workflow_complete":
                print(f"\n\næµå¼å·¥ä½œæµå®Œæˆ")
                break
            elif event["type"] == "workflow_error":
                print(f"\næµå¼å·¥ä½œæµé”™è¯¯: {event['data']['error']}")
                break
        
        full_answer = "".join(answer_chunks)
        print(f"å®Œæ•´ç­”æ¡ˆé•¿åº¦: {len(full_answer)} å­—ç¬¦")
        
        print("âœ… æµå¼å·¥ä½œæµæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æµå¼å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿæµ‹è¯•...\n")
    
    test_results = []
    
    # åŸºç¡€æœåŠ¡æµ‹è¯•
    test_results.append(await test_llm_service())
    print()
    
    test_results.append(await test_embedding_service())
    print()
    
    # æ•°æ®åº“æµ‹è¯•ï¼ˆå¯èƒ½å¤±è´¥ï¼Œå› ä¸ºéœ€è¦å¤–éƒ¨æœåŠ¡ï¼‰
    test_results.append(await test_vector_db())
    print()
    
    test_results.append(await test_graph_db())
    print()
    
    # æ™ºèƒ½ä½“å’Œå·¥ä½œæµæµ‹è¯•
    test_results.append(await test_agents())
    print()
    
    test_results.append(await test_workflow())
    print()
    
    test_results.append(await test_stream_workflow())
    print()
    
    # ç»Ÿè®¡ç»“æœ
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æœåŠ¡é…ç½®ã€‚")
        print("æ³¨æ„ï¼šæ•°æ®åº“ç›¸å…³æµ‹è¯•éœ€è¦Milvuså’ŒNeo4jæœåŠ¡è¿è¡Œã€‚")
    
    return passed == total


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
