"""
è‡ªå®šä¹‰ChatCompletionContextæ¥è§£å†³AutoGençš„memorieså±æ€§é—®é¢˜
æ ¹æ®Microsoft AutoGenå®˜æ–¹æ–‡æ¡£ä¿®å¤UnboundedChatCompletionContextç¼ºå°‘memorieså±æ€§çš„é—®é¢˜
å‚è€ƒ: https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/memory.html
"""
import logging
import sys
import traceback
from typing import List, Sequence, Any, Optional

logger = logging.getLogger(__name__)

# ç›´æ¥å¯¼å…¥ AutoGen ç»„ä»¶
logger.info("ğŸ”§ å¼€å§‹å¯¼å…¥ AutoGen ç»„ä»¶...")

# ç›´æ¥å¯¼å…¥ï¼Œä¸ä½¿ç”¨å¤æ‚çš„é”™è¯¯å¤„ç†
from autogen_agentchat.messages import BaseMessage
from autogen_core.model_context import UnboundedChatCompletionContext
from autogen_core.models import LLMMessage
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient

AUTOGEN_AVAILABLE = True
logger.info("âœ… AutoGen ç»„ä»¶å¯¼å…¥æˆåŠŸ")




class MemoryResult:
    """æ¨¡æ‹Ÿmemories.resultsçš„ç»“æ„"""
    def __init__(self, results: List[Any] = None):
        self.results = results or []


class MemoryContainer:
    """æ¨¡æ‹Ÿmemorieså±æ€§çš„å®¹å™¨ï¼Œç¬¦åˆAutoGen Memoryåè®®"""
    def __init__(self):
        self.results = []
        self.items = []  # å…¼å®¹ä¸åŒçš„è®¿é—®æ–¹å¼
        
    def add_result(self, result: Any):
        """æ·»åŠ è®°å¿†ç»“æœ"""
        self.results.append(result)
        self.items.append(result)
        
    def clear(self):
        """æ¸…ç©ºè®°å¿†"""
        self.results.clear()
        self.items.clear()


class FixedUnboundedChatCompletionContext(UnboundedChatCompletionContext):
    """
    ä¿®å¤äº†memorieså±æ€§é—®é¢˜çš„UnboundedChatCompletionContext
    æ ¹æ®Microsoft AutoGenå®˜æ–¹æ–‡æ¡£å®ç°
    """
    
    def __init__(self, initial_messages: Optional[Sequence[LLMMessage]] = None):
        if not AUTOGEN_AVAILABLE:
            logger.warning("AutoGenä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
            return
            
        super().__init__(initial_messages)
        # æ·»åŠ ç¼ºå¤±çš„memorieså±æ€§
        self.memories = MemoryContainer()
        logger.debug("FixedUnboundedChatCompletionContextåˆå§‹åŒ–å®Œæˆï¼Œå·²æ·»åŠ memorieså±æ€§")
    
    async def add_message(self, message: LLMMessage) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡"""
        if not AUTOGEN_AVAILABLE:
            return
            
        await super().add_message(message)
        logger.debug(f"æ¶ˆæ¯å·²æ·»åŠ åˆ°ä¸Šä¸‹æ–‡: {type(message).__name__}")
    
    async def get_messages(self) -> List[LLMMessage]:
        """è·å–æ‰€æœ‰æ¶ˆæ¯"""
        if not AUTOGEN_AVAILABLE:
            return []
            
        messages = await super().get_messages()
        logger.debug(f"è·å–åˆ° {len(messages)} æ¡æ¶ˆæ¯")
        return messages
    
    def add_memory_result(self, result: Any):
        """æ·»åŠ è®°å¿†ç»“æœåˆ°ä¸Šä¸‹æ–‡"""
        if hasattr(self, 'memories'):
            self.memories.add_result(result)
            logger.debug("è®°å¿†ç»“æœå·²æ·»åŠ åˆ°ä¸Šä¸‹æ–‡")


def create_fixed_assistant(name: str, model_client, system_message: str = None, 
                          tools: List = None, memory_adapters: List = None):
    """
    åˆ›å»ºä½¿ç”¨ä¿®å¤åçš„ChatCompletionContextçš„AssistantAgent
    æ ¹æ®Microsoft AutoGenå®˜æ–¹æ–‡æ¡£å®ç°
    """
    if not AUTOGEN_AVAILABLE:
        logger.warning("AutoGenä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ™ºèƒ½ä½“")
        return None
    
    try:
        # åˆ›å»ºä¿®å¤åçš„model_context
        model_context = FixedUnboundedChatCompletionContext()
        
        # åˆ›å»ºåŠ©æ‰‹å‚æ•°
        assistant_params = {
            "name": name,
            "model_client": model_client,
            "model_context": model_context,  # ä½¿ç”¨æˆ‘ä»¬ä¿®å¤åçš„context
            "reflect_on_tool_use": True,
            "model_client_stream": True,
        }
        
        if system_message:
            assistant_params["system_message"] = system_message
        
        if tools:
            assistant_params["tools"] = tools
        
        if memory_adapters:
            assistant_params["memory"] = memory_adapters
            logger.debug(f"è®°å¿†æœåŠ¡å·²å¯ç”¨ï¼Œé€‚é…å™¨æ•°é‡: {len(memory_adapters)}")
        
        # åˆ›å»ºåŠ©æ‰‹
        assistant = AssistantAgent(**assistant_params)
        
        logger.debug(f"ä¿®å¤åçš„åŠ©æ‰‹åˆ›å»ºæˆåŠŸ: {name}")
        return assistant
        
    except Exception as e:
        logger.error(f"åˆ›å»ºä¿®å¤åçš„åŠ©æ‰‹å¤±è´¥: {e}")
        # å›é€€åˆ°æ ‡å‡†åˆ›å»ºæ–¹å¼
        try:
            assistant_params = {
                "name": name,
                "model_client": model_client,
                "reflect_on_tool_use": True,
                "model_client_stream": True,
            }
            
            if system_message:
                assistant_params["system_message"] = system_message
            
            if tools:
                assistant_params["tools"] = tools
            
            # ä¸ä½¿ç”¨memoryå‚æ•°ï¼Œé¿å…é”™è¯¯
            assistant = AssistantAgent(**assistant_params)
            logger.warning(f"ä½¿ç”¨å›é€€æ–¹å¼åˆ›å»ºåŠ©æ‰‹: {name} (è®°å¿†åŠŸèƒ½å·²ç¦ç”¨)")
            return assistant
            
        except Exception as fallback_error:
            logger.error(f"å›é€€åˆ›å»ºåŠ©æ‰‹ä¹Ÿå¤±è´¥: {fallback_error}")
            return None


class MemoryWorkaroundMixin:
    """
    ä¸ºç°æœ‰çš„å†…å­˜é€‚é…å™¨æ·»åŠ workaroundåŠŸèƒ½çš„æ··å…¥ç±»
    """
    
    async def update_context_safe(self, messages: Sequence[BaseMessage]) -> Sequence[BaseMessage]:
        """
        å®‰å…¨çš„ä¸Šä¸‹æ–‡æ›´æ–°æ–¹æ³•ï¼Œé¿å…memorieså±æ€§é”™è¯¯
        """
        try:
            # è°ƒç”¨åŸå§‹çš„update_contextæ–¹æ³•
            return await self.update_context(messages)
        except AttributeError as e:
            if "memories" in str(e):
                logger.warning(f"æ£€æµ‹åˆ°memorieså±æ€§é”™è¯¯ï¼Œä½¿ç”¨fallbackæ–¹æ³•: {e}")
                # ä½¿ç”¨fallbackæ–¹æ³•ï¼šç›´æ¥è¿”å›åŸå§‹æ¶ˆæ¯
                return messages
            else:
                # å…¶ä»–AttributeErrorç»§ç»­æŠ›å‡º
                raise
        except Exception as e:
            logger.error(f"ä¸Šä¸‹æ–‡æ›´æ–°å¤±è´¥: {e}")
            # è¿”å›åŸå§‹æ¶ˆæ¯ï¼Œç¡®ä¿ä¸ä¸­æ–­æµç¨‹
            return messages


def patch_memory_adapter(adapter):
    """
    ä¸ºå†…å­˜é€‚é…å™¨æ·»åŠ workaroundåŠŸèƒ½
    """
    if not adapter:
        return adapter
        
    # ä¿å­˜åŸå§‹çš„update_contextæ–¹æ³•
    if hasattr(adapter, 'update_context'):
        original_update_context = adapter.update_context
        
        async def safe_update_context(messages: Sequence[BaseMessage]) -> Sequence[BaseMessage]:
            try:
                return await original_update_context(messages)
            except AttributeError as e:
                if "memories" in str(e):
                    logger.warning(f"æ£€æµ‹åˆ°memorieså±æ€§é”™è¯¯ï¼Œè·³è¿‡å†…å­˜æ›´æ–°: {e}")
                    return messages
                else:
                    raise
            except Exception as e:
                logger.error(f"å†…å­˜æ›´æ–°å¤±è´¥: {e}")
                return messages
        
        # æ›¿æ¢update_contextæ–¹æ³•
        adapter.update_context = safe_update_context
        logger.debug("å†…å­˜é€‚é…å™¨å·²åº”ç”¨workaroundè¡¥ä¸")
    
    return adapter


def create_safe_assistant_with_memory(name: str, model_client, system_message: str = None,
                                     tools: List = None, memory_adapters: List = None):
    """
    åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„AssistantAgent
    """
    if not model_client:
        logger.error("âŒ æ¨¡å‹å®¢æˆ·ç«¯ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºæ™ºèƒ½ä½“")
        return None
    
    try:
        # ä½¿ç”¨ç®€åŒ–çš„æ–¹å¼åˆ›å»ºæ™ºèƒ½ä½“
        assistant_params = {
            "name": name,
            "model_client": model_client,
        }

        if system_message:
            assistant_params["system_message"] = system_message

        if tools:
            assistant_params["tools"] = tools

        # åˆ›å»ºæ™ºèƒ½ä½“
        assistant = AssistantAgent(**assistant_params)
        logger.info(f"âœ… æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ: {name}")
        return assistant

    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None
