"""
èŠå¤©æ§åˆ¶å™¨
åŸºäºautogen 0.6.1å’ŒDeepseekæ¨¡å‹å®ç°æ™ºèƒ½å®¢æœåŠŸèƒ½
é›†æˆè®°å¿†æœåŠ¡æä¾›ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›
"""
import asyncio
import time
import uuid
from datetime import datetime
from typing import List, Optional, AsyncGenerator, Tuple, Dict, Any

from autogen_agentchat.base import TaskResult
from autogen_agentchat.messages import TextMessage, ToolCallRequestEvent, ToolCallExecutionEvent, \
    ModelClientStreamingChunkEvent, ToolCallSummaryMessage
from fastapi import HTTPException

from app.core.llm_config import deepseek_config
from app.models.admin import ChatConversation, ChatMessage
from app.schemas.chat import (
    SendMessageRequest,
    StreamMessageChunk
)
from app.services.memory import ConversationMemoryAdapter


class ChatController:
    """èŠå¤©æ§åˆ¶å™¨"""

    def __init__(self):
        # å¯¹è¯å†å²ç¼“å­˜: {conversation_id: message_list}
        self.conversation_history: Dict[str, List[Dict[str, Any]]] = {}
        # è®°å¿†é€‚é…å™¨ç¼“å­˜: {conversation_id: memory_adapter}
        self.memory_adapters: Dict[str, ConversationMemoryAdapter] = {}
        # è®¾ç½®æ¨¡å‹è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.model_timeout = 120

    def get_assistant_with_memory(self, user_id: int, conversation_id: str):
        """è·å–å¸¦è®°å¿†åŠŸèƒ½çš„åŠ©æ‰‹å®ä¾‹"""
        # åˆ›å»ºæˆ–è·å–è®°å¿†é€‚é…å™¨
        if conversation_id not in self.memory_adapters:
            self.memory_adapters[conversation_id] = ConversationMemoryAdapter(
                user_id=str(user_id),
                session_id=conversation_id
            )

        memory_adapter = self.memory_adapters[conversation_id]

        # åˆ›å»ºå¸¦è®°å¿†åŠŸèƒ½çš„åŠ©æ‰‹
        assistant = deepseek_config.get_assistant(memory_adapters=[memory_adapter])

        return assistant, memory_adapter

    async def create_conversation(self, user_id: int, title: str = "") -> ChatConversation:
        """åˆ›å»ºæ–°å¯¹è¯"""
        conversation_id = f"conv_{int(time.time())}_{uuid.uuid4().hex[:8]}"

        conversation = await ChatConversation.create(
            conversation_id=conversation_id,
            user_id=user_id,
            title=title or "æ–°å¯¹è¯",
            is_active=True,
            last_message_at=datetime.now()
        )
        
        # åˆå§‹åŒ–ä¼šè¯å†å²
        self.conversation_history[conversation_id] = []

        return conversation

    async def get_conversation(self, conversation_id: str, user_id: int) -> Optional[ChatConversation]:
        """è·å–å¯¹è¯"""
        return await ChatConversation.filter(
            conversation_id=conversation_id,
            user_id=user_id
        ).first()

    async def get_user_conversations(
            self,
            user_id: int,
            page: int = 1,
            page_size: int = 20
    ) -> Tuple[int, List[ChatConversation]]:
        """è·å–ç”¨æˆ·å¯¹è¯åˆ—è¡¨"""
        offset = (page - 1) * page_size

        total = await ChatConversation.filter(user_id=user_id).count()
        conversations = await ChatConversation.filter(
            user_id=user_id
        ).order_by('-last_message_at').offset(offset).limit(page_size)

        return total, conversations

    async def save_message(
            self,
            conversation_id: str,
            user_id: int,
            content: str,
            sender: str,
            message_type: str = "text",
            tokens_used: int = 0,
            response_time: int = 0
    ) -> ChatMessage:
        """ä¿å­˜æ¶ˆæ¯"""
        message_id = f"msg_{int(time.time())}_{uuid.uuid4().hex[:8]}"

        message = await ChatMessage.create(
            conversation_id=conversation_id,
            message_id=message_id,
            user_id=user_id,
            sender=sender,
            content=content,
            message_type=message_type,
            tokens_used=tokens_used,
            response_time=response_time
        )

        # æ›´æ–°å¯¹è¯çš„æœ€åæ¶ˆæ¯æ—¶é—´
        await ChatConversation.filter(
            conversation_id=conversation_id
        ).update(last_message_at=datetime.now())

        return message

    async def get_conversation_messages(
            self,
            conversation_id: str,
            user_id: int,
            limit: int = 50
    ) -> List[ChatMessage]:
        """è·å–å¯¹è¯æ¶ˆæ¯å†å²"""
        messages = await ChatMessage.filter(
            conversation_id=conversation_id,
            user_id=user_id
        ).order_by('created_at').limit(limit)
        
        # å¦‚æœä¸åœ¨å†…å­˜ç¼“å­˜ä¸­ï¼Œåˆ™åŠ è½½å†å²è®°å½•åˆ°ç¼“å­˜
        if conversation_id not in self.conversation_history:
            self.conversation_history[conversation_id] = []
            for msg in messages:
                self.conversation_history[conversation_id].append({
                    "role": msg.sender,
                    "content": msg.content
                })
                
        return messages

    async def _prepare_conversation_history(self, conversation_id: str, user_id: int) -> None:
        """å‡†å¤‡å¯¹è¯å†å²ä»¥ä¾›æ¨¡å‹ä½¿ç”¨"""
        if conversation_id not in self.conversation_history:
            await self.get_conversation_messages(conversation_id, user_id)

    async def send_message_stream(
            self,
            request: SendMessageRequest,
            user_id: int
    ) -> AsyncGenerator[StreamMessageChunk, None]:
        """å‘é€æ¶ˆæ¯å¹¶è¿”å›æµå¼å“åº”ï¼ˆä½¿ç”¨Deepseekæ¨¡å‹å’Œè®°å¿†æœåŠ¡ï¼‰"""
        start_time = time.time()

        # è·å–æˆ–åˆ›å»ºå¯¹è¯
        if request.conversation_id:
            conversation = await self.get_conversation(request.conversation_id, user_id)
            if not conversation:
                raise HTTPException(status_code=404, detail="å¯¹è¯ä¸å­˜åœ¨")
        else:
            conversation = await self.create_conversation(user_id)

        # è·å–å¸¦è®°å¿†åŠŸèƒ½çš„åŠ©æ‰‹
        assistant, memory_adapter = self.get_assistant_with_memory(user_id, conversation.conversation_id)

        # å‡†å¤‡å¯¹è¯å†å²
        await self._prepare_conversation_history(conversation.conversation_id, user_id)

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_message = await self.save_message(
            conversation_id=conversation.conversation_id,
            user_id=user_id,
            content=request.message,
            sender="user"
        )

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°è®°å¿†æœåŠ¡
        await memory_adapter.add_conversation_message(
            role="user",
            content=request.message,
            metadata={"message_id": user_message.message_id}
        )

        # æ›´æ–°å¯¹è¯å†å²
        if conversation.conversation_id not in self.conversation_history:
            self.conversation_history[conversation.conversation_id] = []
        self.conversation_history[conversation.conversation_id].append({
            "role": "user",
            "content": request.message
        })

        # ä¸å‘é€ç”¨æˆ·æ¶ˆæ¯å›æ˜¾ï¼Œé¿å…é‡å¤æ˜¾ç¤º

        # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å¯¹è±¡
        user_task = TextMessage(source="user", content=request.message)

        # ç”ŸæˆåŠ©æ‰‹æ¶ˆæ¯ID
        assistant_message_id = f"msg_{int(time.time())}_{uuid.uuid4().hex[:8]}"

        # æµå¼å“åº”å¤„ç†å˜é‡
        response_content = ""
        total_tokens_used = 0
        tool_call_status_sent = False

        # å†…å®¹ç¼“å†²åŒºï¼Œç”¨äºä¼˜åŒ–åˆ†å—
        content_buffer = ""
        buffer_size_threshold = 10  # ç¼“å†²åŒºå¤§å°é˜ˆå€¼ï¼ˆå­—ç¬¦æ•°ï¼‰
        word_boundary_chars = {' ', 'ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼š', '\n', '\t'}  # è¯è¯­è¾¹ç•Œå­—ç¬¦
        
        async def flush_buffer():
            """åˆ·æ–°ç¼“å†²åŒºï¼Œå‘é€ç´¯ç§¯çš„å†…å®¹"""
            nonlocal content_buffer
            if content_buffer:
                yield StreamMessageChunk(
                    conversation_id=conversation.conversation_id,
                    message_id=assistant_message_id,
                    content=content_buffer,
                    is_complete=False,
                    timestamp=datetime.now(),
                    sender="assistant"
                )
                content_buffer = ""

        async def add_to_buffer(text: str):
            """æ·»åŠ æ–‡æœ¬åˆ°ç¼“å†²åŒºï¼Œæ™ºèƒ½åˆ†å—"""
            nonlocal content_buffer
            content_buffer += text

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ·æ–°ç¼“å†²åŒº
            should_flush = False

            # æ¡ä»¶1: ç¼“å†²åŒºè¾¾åˆ°å¤§å°é˜ˆå€¼
            if len(content_buffer) >= buffer_size_threshold:
                should_flush = True

            # æ¡ä»¶2: é‡åˆ°è¯è¯­è¾¹ç•Œå­—ç¬¦
            if text and text[-1] in word_boundary_chars:
                should_flush = True

            # æ¡ä»¶3: é‡åˆ°å®Œæ•´çš„å¥å­ç»“æŸ
            if any(char in text for char in {'ã€‚', 'ï¼', 'ï¼Ÿ', '\n'}):
                should_flush = True

            if should_flush:
                async for chunk in flush_buffer():
                    yield chunk

        try:
            # è·å–æµå¼å“åº”ï¼ˆä½¿ç”¨å¸¦è®°å¿†çš„åŠ©æ‰‹ï¼‰
            stream = assistant.run_stream(task=user_task)

            # å¤„ç†æµå¼å“åº”
            async for event in stream:
                try:
                    # é€šç”¨è¿‡æ»¤ï¼šè·³è¿‡ä»»ä½•åŒ…å«ç”¨æˆ·æ¶ˆæ¯å†…å®¹çš„äº‹ä»¶
                    if hasattr(event, 'content') and isinstance(event.content, str):
                        if event.content.strip() == request.message.strip():
                            continue
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆç»“æœ
                    if isinstance(event, TaskResult):
                        # åˆ·æ–°å‰©ä½™ç¼“å†²åŒºå†…å®¹
                        async for chunk in flush_buffer():
                            yield chunk

                        # è®¡ç®—å“åº”æ—¶é—´
                        response_time = int((time.time() - start_time) * 1000)

                        # ä¿å­˜å®Œæ•´çš„åŠ©æ‰‹å›å¤
                        assistant_message = await self.save_message(
                            conversation_id=conversation.conversation_id,
                            user_id=user_id,
                            content=response_content,
                            sender="assistant",
                            response_time=response_time,
                            tokens_used=total_tokens_used
                        )

                        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°è®°å¿†æœåŠ¡
                        await memory_adapter.add_conversation_message(
                            role="assistant",
                            content=response_content,
                            metadata={
                                "message_id": assistant_message.message_id,
                                "response_time": response_time,
                                "tokens_used": total_tokens_used
                            }
                        )

                        # æ›´æ–°ä¼šè¯å†å²
                        self.conversation_history[conversation.conversation_id].append({
                            "role": "assistant",
                            "content": response_content
                        })

                        # å‘é€å®Œæˆæ ‡å¿—
                        yield StreamMessageChunk(
                            conversation_id=conversation.conversation_id,
                            message_id=assistant_message_id,
                            content="",
                            is_complete=True,
                            timestamp=datetime.now(),
                            sender="assistant"
                        )

                    elif isinstance(event, ModelClientStreamingChunkEvent):
                        # æµå¼è¾“å‡ºæ–‡æœ¬å— - è¿™æ˜¯ä¸»è¦çš„æµå¼å†…å®¹
                        chunk_content = event.content
                        if chunk_content:  # åªå¤„ç†éç©ºå†…å®¹
                            response_content += chunk_content
                            # ä½¿ç”¨æ™ºèƒ½ç¼“å†²åŒºå¤„ç†
                            async for buffered_chunk in add_to_buffer(chunk_content):
                                yield buffered_chunk

                    elif isinstance(event, TextMessage):
                        # å®Œæ•´æ–‡æœ¬æ¶ˆæ¯ - é€šå¸¸åœ¨å·¥å…·è°ƒç”¨åå‡ºç°
                        # ä¸¥æ ¼è¿‡æ»¤ï¼šåªå¤„ç†æ¥è‡ªåŠ©æ‰‹çš„æ¶ˆæ¯ï¼Œé¿å…ç”¨æˆ·æ¶ˆæ¯å›æ˜¾
                        if hasattr(event, 'source') and event.source == 'user':
                            # è·³è¿‡ç”¨æˆ·æ¶ˆæ¯ï¼Œé¿å…å›æ˜¾
                            continue
                            
                        msg_content = event.content
                        if msg_content:
                            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ç”¨æˆ·è¾“å…¥ç›¸åŒï¼Œå¦‚æœç›¸åŒåˆ™è·³è¿‡
                            if msg_content.strip() == request.message.strip():
                                continue
                                
                            # å¦‚æœå·²ç»æœ‰æµå¼å†…å®¹ï¼Œä¸å†å‘é€å®Œæ•´æ¶ˆæ¯ï¼Œé¿å…é‡å¤
                            if not response_content:
                                response_content = msg_content
                                # ä½¿ç”¨æ™ºèƒ½ç¼“å†²åŒºå¤„ç†å®Œæ•´æ¶ˆæ¯
                                async for buffered_chunk in add_to_buffer(msg_content):
                                    yield buffered_chunk

                        # å¤„ç†tokenä½¿ç”¨ç»Ÿè®¡
                        if hasattr(event, 'models_usage') and event.models_usage:
                            if hasattr(event.models_usage, 'prompt_tokens'):
                                total_tokens_used += event.models_usage.prompt_tokens + (event.models_usage.completion_tokens or 0)
                    
                    elif isinstance(event, ToolCallRequestEvent):
                        # å·¥å…·è°ƒç”¨è¯·æ±‚ - åªå‘é€ä¸€æ¬¡çŠ¶æ€æç¤º
                        if not tool_call_status_sent:
                            tool_calls = event.content
                            tool_names = []
                            for call in tool_calls:
                                if hasattr(call, 'name'):
                                    tool_names.append(call.name)

                            if tool_names:
                                tool_call_msg = f"ğŸ” æ­£åœ¨æŸ¥è¯¢ç›¸å…³ä¿¡æ¯ï¼ˆ{', '.join(tool_names)}ï¼‰..."
                            else:
                                tool_call_msg = "ğŸ” æ­£åœ¨æŸ¥è¯¢ç›¸å…³ä¿¡æ¯..."

                            # å·¥å…·è°ƒç”¨çŠ¶æ€ä½œä¸ºç‹¬ç«‹çš„chunkå‘é€
                            yield StreamMessageChunk(
                                conversation_id=conversation.conversation_id,
                                message_id=assistant_message_id,
                                content=tool_call_msg,
                                is_complete=False,
                                timestamp=datetime.now(),
                                sender="assistant"
                            )
                            tool_call_status_sent = True

                    elif isinstance(event, ToolCallExecutionEvent):
                        # å·¥å…·è°ƒç”¨ç»“æœ - ä¸å†å‘é€æ‰§è¡Œç»“æœæ¦‚è¦ï¼Œé¿å…é‡å¤å†…å®¹
                        # è®©AIåœ¨æœ€ç»ˆå›å¤ä¸­æ•´åˆæ‰€æœ‰ä¿¡æ¯
                        pass

                    elif isinstance(event, ToolCallSummaryMessage):
                        # å·¥å…·è°ƒç”¨æ‘˜è¦ - é€šå¸¸åŒ…å«å·¥å…·è°ƒç”¨çš„æ±‡æ€»ä¿¡æ¯
                        # è¿™é‡Œä¸å†å•ç‹¬å‘é€æ‘˜è¦ï¼Œè®©AIåœ¨æœ€ç»ˆå›å¤ä¸­æ•´åˆä¿¡æ¯
                        pass
                        
                except asyncio.TimeoutError:
                    raise Exception("å•æ­¥å¤„ç†è¶…æ—¶ã€‚")
                except Exception as e:
                    raise Exception(f"å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {str(e)}")
                    
        except Exception as e:
            # åˆ·æ–°ä»»ä½•å‰©ä½™çš„ç¼“å†²åŒºå†…å®¹
            try:
                async for chunk in flush_buffer():
                    yield chunk
            except:
                pass

            # é”™è¯¯å¤„ç†
            error_message = f"ğŸ˜” æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»äººå·¥å®¢æœã€‚\n\né”™è¯¯è¯¦æƒ…ï¼š{str(e)}"

            await self.save_message(
                conversation_id=conversation.conversation_id,
                user_id=user_id,
                content=error_message,
                sender="assistant",
                response_time=int((time.time() - start_time) * 1000)
            )

            yield StreamMessageChunk(
                conversation_id=conversation.conversation_id,
                message_id=f"error_{int(time.time())}",
                content=error_message,
                is_complete=True,
                timestamp=datetime.now(),
                sender="assistant"
            )

    async def delete_conversation(self, conversation_id: str, user_id: int) -> bool:
        """åˆ é™¤å¯¹è¯"""
        conversation = await self.get_conversation(conversation_id, user_id)
        if not conversation:
            return False

        # åˆ é™¤å¯¹è¯ç›¸å…³çš„æ‰€æœ‰æ¶ˆæ¯
        await ChatMessage.filter(conversation_id=conversation_id).delete()

        # åˆ é™¤å¯¹è¯
        await conversation.delete()
        
        # åˆ é™¤å†…å­˜ä¸­çš„ä¼šè¯å†å²
        if conversation_id in self.conversation_history:
            del self.conversation_history[conversation_id]

        # æ¸…ç†è®°å¿†é€‚é…å™¨
        if conversation_id in self.memory_adapters:
            await self.memory_adapters[conversation_id].close()
            del self.memory_adapters[conversation_id]

        return True

    async def update_conversation_title(
            self,
            conversation_id: str,
            user_id: int,
            title: str
    ) -> bool:
        """æ›´æ–°å¯¹è¯æ ‡é¢˜"""
        conversation = await self.get_conversation(conversation_id, user_id)
        if not conversation:
            return False

        conversation.title = title
        await conversation.save()

        return True


# å…¨å±€èŠå¤©æ§åˆ¶å™¨å®ä¾‹
chat_controller = ChatController()
