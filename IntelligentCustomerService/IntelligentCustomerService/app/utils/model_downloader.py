"""
æ¨¡å‹ä¸‹è½½å·¥å…·
ä»é­”å¡”ç¤¾åŒº(ModelScope)ä¸‹è½½Qwen3-8BåµŒå…¥æ¨¡å‹å’ŒQwen3-Reranker-8Bé‡æ’æ¨¡å‹
"""
import asyncio
import logging
import os
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Optional, Dict, Any

try:
    from modelscope import snapshot_download
    from modelscope.hub.api import HubApi
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False
    snapshot_download = None
    HubApi = None

logger = logging.getLogger(__name__)


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨ - ä»é­”å¡”ç¤¾åŒºä¸‹è½½æ¨¡å‹"""
    
    def __init__(self, cache_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¸‹è½½å™¨

        Args:
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„modelsæ–‡ä»¶å¤¹
        """

        # è®¾ç½®ç¼“å­˜ç›®å½•
        if cache_dir is None:
            project_root = Path(__file__).parent.parent.parent
            cache_dir = project_root / "models"

        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®ModelScopeç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨é¡¹ç›®ç›®å½•
        import os
        os.environ['MODELSCOPE_CACHE'] = str(self.cache_dir)
        os.environ['HF_HOME'] = str(self.cache_dir)  # ä¹Ÿè®¾ç½®HuggingFaceç¼“å­˜ç›®å½•
        logger.info(f"è®¾ç½®ModelScopeç¼“å­˜ç›®å½•: {self.cache_dir}")
        
        # æ¨¡å‹é…ç½® - ä½¿ç”¨é­”å¡”ç¤¾åŒºçš„Qwenæ¨¡å‹
        self.models_config = {
            "embedding": {
                "model_id": "Qwen/Qwen3-0.6B",  # é­”å¡”ç¤¾åŒºQwen3-0.6Bæ¨¡å‹
                "model_name": "Qwen3-0.6B",
                "description": "Qwen3-0.6BåµŒå…¥æ¨¡å‹",
                "cache_subdir": "embedding"
            },
            "reranker": {
                "model_id": "Qwen/Qwen3-Reranker-0.6B",  # é­”å¡”ç¤¾åŒºQwen3-Reranker-0.6Bæ¨¡å‹
                "model_name": "Qwen3-Reranker-0.6B",
                "description": "Qwen3-Reranker-0.6Bé‡æ’æ¨¡å‹",
                "cache_subdir": "reranker"
            }
        }
        
        logger.info(f"æ¨¡å‹ä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆï¼Œç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def get_model_cache_path(self, model_type: str) -> Path:
        """è·å–æ¨¡å‹ç¼“å­˜è·¯å¾„"""
        if model_type not in self.models_config:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        config = self.models_config[model_type]
        return self.cache_dir / config["cache_subdir"] / config["model_name"]
    
    def is_model_cached(self, model_type: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜"""
        model_path = self.get_model_cache_path(model_type)
        return model_path.exists() and any(model_path.iterdir())
    
    async def download_model_async(self, model_type: str, force_download: bool = False) -> str:
        """å¼‚æ­¥ä¸‹è½½æ¨¡å‹"""
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            return await loop.run_in_executor(
                executor, 
                self.download_model, 
                model_type, 
                force_download
            )
    
    def download_model(self, model_type: str, force_download: bool = False) -> str:
        """
        ä¸‹è½½æŒ‡å®šç±»å‹çš„æ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('embedding' æˆ– 'reranker')
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            æ¨¡å‹æœ¬åœ°è·¯å¾„
        """
        if model_type not in self.models_config:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}ï¼Œæ”¯æŒçš„ç±»å‹: {list(self.models_config.keys())}")
        
        config = self.models_config[model_type]
        model_path = self.get_model_cache_path(model_type)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜
        if not force_download and self.is_model_cached(model_type):
            logger.info(f"âœ… {config['description']}å·²ç¼“å­˜: {model_path}")
            return str(model_path)
        
        logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½{config['description']}...")
        logger.info(f"ğŸ“ æ¨¡å‹ID: {config['model_id']}")
        logger.info(f"ğŸ“ ç¼“å­˜è·¯å¾„: {model_path}")
        
        try:
            # åˆ›å»ºç¼“å­˜ç›®å½•
            model_path.mkdir(parents=True, exist_ok=True)

            # ä»é­”å¡”ç¤¾åŒºä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
            # ç¯å¢ƒå˜é‡å·²åœ¨__init__ä¸­è®¾ç½®ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨local_dirå‚æ•°
            downloaded_path = snapshot_download(
                model_id=config['model_id'],
                local_dir=str(model_path),      # æŒ‡å®šæœ¬åœ°å­˜å‚¨ç›®å½•
                revision='master'
            )

            logger.info(f"âœ… {config['description']}ä¸‹è½½å®Œæˆ: {downloaded_path}")
            return downloaded_path

        except Exception as e:
            logger.error(f"âŒ {config['description']}ä¸‹è½½å¤±è´¥: {e}")
            raise
    
    def download_all_models(self, force_download: bool = False) -> Dict[str, str]:
        """
        ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        
        Args:
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            æ¨¡å‹ç±»å‹åˆ°è·¯å¾„çš„æ˜ å°„
        """
        results = {}
        
        for model_type in self.models_config.keys():
            try:
                model_path = self.download_model(model_type, force_download)
                results[model_type] = model_path
            except Exception as e:
                logger.error(f"ä¸‹è½½{model_type}æ¨¡å‹å¤±è´¥: {e}")
                results[model_type] = None
        
        return results
    
    async def download_all_models_async(self, force_download: bool = False) -> Dict[str, str]:
        """å¼‚æ­¥ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        tasks = []
        for model_type in self.models_config.keys():
            task = self.download_model_async(model_type, force_download)
            tasks.append((model_type, task))
        
        results = {}
        for model_type, task in tasks:
            try:
                model_path = await task
                results[model_type] = model_path
            except Exception as e:
                logger.error(f"å¼‚æ­¥ä¸‹è½½{model_type}æ¨¡å‹å¤±è´¥: {e}")
                results[model_type] = None
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            "cache_dir": str(self.cache_dir),
            "models": {},
            "total_cache_size": 0,
            "modelscope_config": {
                "cache_env": os.environ.get('MODELSCOPE_CACHE', 'Not Set'),
                "hf_home_env": os.environ.get('HF_HOME', 'Not Set')
            }
        }

        total_size = 0
        for model_type, config in self.models_config.items():
            model_path = self.get_model_cache_path(model_type)
            is_cached = self.is_model_cached(model_type)
            cache_size = self._get_directory_size(model_path) if is_cached else 0
            total_size += cache_size

            info["models"][model_type] = {
                "model_id": config["model_id"],
                "model_name": config["model_name"],
                "description": config["description"],
                "cache_path": str(model_path),
                "is_cached": is_cached,
                "cache_size": cache_size,
                "cache_size_mb": round(cache_size / (1024 * 1024), 2),
                "last_modified": self._get_last_modified(model_path) if is_cached else None
            }

        info["total_cache_size"] = total_size
        info["total_cache_size_mb"] = round(total_size / (1024 * 1024), 2)

        return info
    
    def _get_directory_size(self, path: Path) -> int:
        """è·å–ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        if not path.exists():
            return 0

        total_size = 0
        try:
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except Exception as e:
            logger.warning(f"è®¡ç®—ç›®å½•å¤§å°å¤±è´¥: {e}")

        return total_size

    def _get_last_modified(self, path: Path) -> str:
        """è·å–ç›®å½•æœ€åä¿®æ”¹æ—¶é—´"""
        if not path.exists():
            return None

        try:
            # è·å–ç›®å½•ä¸­æœ€æ–°æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
            latest_time = 0
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    file_time = file_path.stat().st_mtime
                    if file_time > latest_time:
                        latest_time = file_time

            if latest_time > 0:
                from datetime import datetime
                return datetime.fromtimestamp(latest_time).isoformat()
        except Exception as e:
            logger.warning(f"è·å–æœ€åä¿®æ”¹æ—¶é—´å¤±è´¥: {e}")

        return None

    def get_download_progress(self, model_type: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¸‹è½½è¿›åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        if model_type not in self.models_config:
            return {"status": "unknown", "progress": 0}

        model_path = self.get_model_cache_path(model_type)
        if self.is_model_cached(model_type):
            return {"status": "completed", "progress": 100}
        elif model_path.exists():
            return {"status": "downloading", "progress": 50}  # ç®€åŒ–çš„è¿›åº¦ä¼°ç®—
        else:
            return {"status": "not_started", "progress": 0}

    def validate_model_integrity(self, model_type: str) -> bool:
        """éªŒè¯æ¨¡å‹å®Œæ•´æ€§"""
        if not self.is_model_cached(model_type):
            return False

        model_path = self.get_model_cache_path(model_type)
        try:
            # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = ['config.json', 'pytorch_model.bin']  # æˆ–å…¶ä»–å¿…éœ€æ–‡ä»¶
            for file_name in required_files:
                file_path = model_path / file_name
                if not file_path.exists():
                    # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
                    model_files = list(model_path.glob('*.bin')) + list(model_path.glob('*.safetensors'))
                    if not model_files:
                        logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´: {model_path}")
                        return False

            return True
        except Exception as e:
            logger.error(f"éªŒè¯æ¨¡å‹å®Œæ•´æ€§å¤±è´¥: {e}")
            return False
    
    def clear_cache(self, model_type: Optional[str] = None):
        """
        æ¸…ç†æ¨¡å‹ç¼“å­˜
        
        Args:
            model_type: è¦æ¸…ç†çš„æ¨¡å‹ç±»å‹ï¼ŒNoneè¡¨ç¤ºæ¸…ç†æ‰€æœ‰
        """
        if model_type is None:
            # æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜
            for mt in self.models_config.keys():
                self._clear_model_cache(mt)
        else:
            self._clear_model_cache(model_type)
    
    def _clear_model_cache(self, model_type: str):
        """æ¸…ç†æŒ‡å®šæ¨¡å‹çš„ç¼“å­˜"""
        if model_type not in self.models_config:
            logger.warning(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
            return
        
        model_path = self.get_model_cache_path(model_type)
        if model_path.exists():
            import shutil
            try:
                shutil.rmtree(model_path)
                logger.info(f"ğŸ§¹ å·²æ¸…ç†{self.models_config[model_type]['description']}ç¼“å­˜")
            except Exception as e:
                logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


# å…¨å±€æ¨¡å‹ä¸‹è½½å™¨å®ä¾‹
_model_downloader = None

def get_model_downloader(cache_dir: Optional[str] = None) -> ModelDownloader:
    """è·å–å…¨å±€æ¨¡å‹ä¸‹è½½å™¨å®ä¾‹"""
    global _model_downloader
    if _model_downloader is None:
        _model_downloader = ModelDownloader(cache_dir)
    return _model_downloader
