"""
å¤šæ¨¡æ€æ™ºèƒ½ä½“
è´Ÿè´£å¤„ç†åŒ…å«å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šåª’ä½“å†…å®¹çš„ç”¨æˆ·è¯·æ±‚
"""

import asyncio
import base64
import logging
from typing import Any, Dict, List, Optional, Union, Tuple
from datetime import datetime
import mimetypes
import os
from pathlib import Path

from autogen_core import CancellationToken
from PIL import Image
import io

from .base_agent import BaseAgent
from ..core.model_manager import model_manager, ModelType

logger = logging.getLogger(__name__)


class MediaProcessor:
    """åª’ä½“å¤„ç†å™¨"""
    
    @staticmethod
    def is_image(file_path_or_data: Union[str, bytes]) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶"""
        if isinstance(file_path_or_data, str):
            mime_type, _ = mimetypes.guess_type(file_path_or_data)
            return mime_type and mime_type.startswith('image/')
        elif isinstance(file_path_or_data, bytes):
            try:
                Image.open(io.BytesIO(file_path_or_data))
                return True
            except Exception:
                return False
        return False
    
    @staticmethod
    def is_video(file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type and mime_type.startswith('video/')
    
    @staticmethod
    def is_audio(file_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶"""
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type and mime_type.startswith('audio/')
    
    @staticmethod
    async def process_image(image_data: Union[str, bytes], max_size: Tuple[int, int] = (1024, 1024)) -> bytes:
        """å¤„ç†å›¾åƒæ•°æ®"""
        try:
            if isinstance(image_data, str):
                # æ–‡ä»¶è·¯å¾„
                with open(image_data, 'rb') as f:
                    image_bytes = f.read()
            else:
                # å­—èŠ‚æ•°æ®
                image_bytes = image_data
            
            # ä½¿ç”¨PILå¤„ç†å›¾åƒ
            image = Image.open(io.BytesIO(image_bytes))
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # è°ƒæ•´å¤§å°
            image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # è½¬æ¢ä¸ºå­—èŠ‚
            output = io.BytesIO()
            image.save(output, format='JPEG', quality=85)
            
            return output.getvalue()
            
        except Exception as e:
            logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")
            raise
    
    @staticmethod
    def encode_image_to_base64(image_data: bytes) -> str:
        """å°†å›¾åƒç¼–ç ä¸ºbase64"""
        return base64.b64encode(image_data).decode('utf-8')
    
    @staticmethod
    def create_data_url(image_data: bytes, mime_type: str = "image/jpeg") -> str:
        """åˆ›å»ºdata URL"""
        base64_data = MediaProcessor.encode_image_to_base64(image_data)
        return f"data:{mime_type};base64,{base64_data}"


class MultimodalAgent(BaseAgent):
    """
    å¤šæ¨¡æ€æ™ºèƒ½ä½“
    
    ä¸»è¦èŒè´£ï¼š
    - å¤„ç†åŒ…å«å›¾åƒçš„ç”¨æˆ·è¯·æ±‚
    - åˆ†æå›¾åƒå†…å®¹å¹¶æä¾›æè¿°
    - å›ç­”å…³äºå›¾åƒçš„é—®é¢˜
    - å¤„ç†è§†é¢‘å’ŒéŸ³é¢‘å†…å®¹ï¼ˆæœªæ¥æ‰©å±•ï¼‰
    - å¤šæ¨¡æ€å†…å®¹çš„ç†è§£å’Œç”Ÿæˆ
    """
    
    def __init__(
        self,
        name: str = "MultimodalAgent",
        system_message: str = None,
        model_config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€æ™ºèƒ½ä½“
        
        Args:
            name: æ™ºèƒ½ä½“åç§°
            system_message: ç³»ç»Ÿæç¤ºè¯
            model_config: æ¨¡å‹é…ç½®
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        if system_message is None:
            system_message = self._get_default_system_message()
        
        super().__init__(
            name=name,
            system_message=system_message,
            model_config=model_config,
            **kwargs
        )
        
        # å¤šæ¨¡æ€é…ç½®
        self.max_image_size = model_config.get('max_image_size', (1024, 1024)) if model_config else (1024, 1024)
        self.supported_formats = model_config.get('supported_formats', ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp']) if model_config else ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp']
        self.max_file_size = model_config.get('max_file_size', 10 * 1024 * 1024) if model_config else 10 * 1024 * 1024  # 10MB
        
        # åª’ä½“å¤„ç†å™¨
        self.media_processor = MediaProcessor()
        
        # å¤šæ¨¡æ€æ¨¡å‹æœåŠ¡
        self.multimodal_service = None
        
        # å¤„ç†ç»Ÿè®¡
        self.image_processed = 0
        self.video_processed = 0
        self.audio_processed = 0
        
        logger.info(f"å¤šæ¨¡æ€æ™ºèƒ½ä½“ {self.name} åˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_system_message(self) -> str:
        """è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤šæ¨¡æ€AIåŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. åˆ†æå’Œç†è§£ç”¨æˆ·ä¸Šä¼ çš„å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šåª’ä½“å†…å®¹
2. æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å†…å®¹æè¿°å’Œåˆ†æ
3. å›ç­”ç”¨æˆ·å…³äºå¤šåª’ä½“å†…å®¹çš„é—®é¢˜
4. è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ã€æ–‡å­—ã€åœºæ™¯ç­‰ä¿¡æ¯
5. æä¾›æœ‰ç”¨çš„å»ºè®®å’Œè§è§£

ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
- å›¾åƒè¯†åˆ«å’Œåˆ†æ
- æ–‡å­—è¯†åˆ«ï¼ˆOCRï¼‰
- åœºæ™¯ç†è§£
- å¯¹è±¡æ£€æµ‹
- æƒ…æ„Ÿåˆ†æ
- å†…å®¹æ€»ç»“

è¯·å§‹ç»ˆæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„åˆ†æç»“æœï¼Œå¦‚æœæ— æ³•ç¡®å®šæŸäº›ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚"""
    
    async def initialize_services(self):
        """åˆå§‹åŒ–æœåŠ¡ä¾èµ–"""
        try:
            # è·å–å¤šæ¨¡æ€æ¨¡å‹æœåŠ¡
            self.multimodal_service = model_manager.get_default_model(ModelType.MULTIMODAL)
            if not self.multimodal_service:
                logger.warning("å¤šæ¨¡æ€æ¨¡å‹æœåŠ¡ä¸å¯ç”¨ï¼Œå°†å½±å“å›¾åƒåˆ†æåŠŸèƒ½")
            
            logger.info(f"å¤šæ¨¡æ€æ™ºèƒ½ä½“ {self.name} æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€æ™ºèƒ½ä½“æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def _handle_message(
        self,
        message: str,
        context: Optional[Dict[str, Any]] = None,
        cancellation_token: Optional[CancellationToken] = None
    ) -> str:
        """
        å¤„ç†å¤šæ¨¡æ€è¯·æ±‚çš„æ ¸å¿ƒé€»è¾‘
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å«å¤šåª’ä½“æ–‡ä»¶ï¼‰
            cancellation_token: å–æ¶ˆä»¤ç‰Œ
            
        Returns:
            å¤šæ¨¡æ€åˆ†æç»“æœ
        """
        try:
            # ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–
            if not self.multimodal_service:
                await self.initialize_services()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šåª’ä½“å†…å®¹
            media_content = await self._extract_media_content(context)
            
            if not media_content:
                return "æˆ‘æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å›¾åƒã€è§†é¢‘æˆ–éŸ³é¢‘å†…å®¹ã€‚è¯·ä¸Šä¼ å¤šåª’ä½“æ–‡ä»¶ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ†æã€‚"
            
            # å¤„ç†ä¸åŒç±»å‹çš„åª’ä½“å†…å®¹
            analysis_results = []
            
            for media_item in media_content:
                media_type = media_item['type']
                
                if media_type == 'image':
                    result = await self._analyze_image(media_item, message, context)
                    analysis_results.append(result)
                elif media_type == 'video':
                    result = await self._analyze_video(media_item, message, context)
                    analysis_results.append(result)
                elif media_type == 'audio':
                    result = await self._analyze_audio(media_item, message, context)
                    analysis_results.append(result)
            
            # ç”Ÿæˆç»¼åˆå›ç­”
            response = await self._generate_multimodal_response(
                message, analysis_results, context
            )
            
            return response
            
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€å¤„ç†å¤±è´¥: {str(e)}")
            return f"æŠ±æ­‰ï¼Œåœ¨å¤„ç†å¤šåª’ä½“å†…å®¹æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{str(e)}"
    
    async def _extract_media_content(self, context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """æå–å¤šåª’ä½“å†…å®¹"""
        media_content = []
        
        if not context:
            return media_content
        
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–å›¾åƒ
        images = context.get('images', [])
        for image in images:
            media_content.append({
                'type': 'image',
                'data': image.get('data'),
                'filename': image.get('filename', ''),
                'mime_type': image.get('mime_type', 'image/jpeg')
            })
        
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–æ–‡ä»¶
        files = context.get('files', [])
        for file_info in files:
            file_path = file_info.get('path', '')
            filename = file_info.get('filename', '')
            
            if self.media_processor.is_image(file_path):
                media_content.append({
                    'type': 'image',
                    'path': file_path,
                    'filename': filename,
                    'mime_type': file_info.get('mime_type', 'image/jpeg')
                })
            elif self.media_processor.is_video(file_path):
                media_content.append({
                    'type': 'video',
                    'path': file_path,
                    'filename': filename,
                    'mime_type': file_info.get('mime_type', 'video/mp4')
                })
            elif self.media_processor.is_audio(file_path):
                media_content.append({
                    'type': 'audio',
                    'path': file_path,
                    'filename': filename,
                    'mime_type': file_info.get('mime_type', 'audio/mpeg')
                })
        
        return media_content
    
    async def _analyze_image(
        self,
        image_item: Dict[str, Any],
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """åˆ†æå›¾åƒå†…å®¹"""
        try:
            self.image_processed += 1
            
            # è·å–å›¾åƒæ•°æ®
            if 'data' in image_item:
                image_data = image_item['data']
            elif 'path' in image_item:
                with open(image_item['path'], 'rb') as f:
                    image_data = f.read()
            else:
                raise ValueError("å›¾åƒæ•°æ®ä¸å¯ç”¨")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if len(image_data) > self.max_file_size:
                raise ValueError(f"å›¾åƒæ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {self.max_file_size / 1024 / 1024:.1f}MB")
            
            # å¤„ç†å›¾åƒ
            processed_image = await self.media_processor.process_image(
                image_data, self.max_image_size
            )
            
            # ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹åˆ†æ
            if self.multimodal_service:
                # æ„å»ºåˆ†ææç¤ºè¯
                analysis_prompt = self._build_image_analysis_prompt(user_message)
                
                # è°ƒç”¨å¤šæ¨¡æ€æ¨¡å‹
                analysis_result = await self.multimodal_service.analyze_image(
                    image_data=processed_image,
                    prompt=analysis_prompt
                )
                
                return {
                    'type': 'image',
                    'filename': image_item.get('filename', 'æœªçŸ¥å›¾åƒ'),
                    'analysis': analysis_result,
                    'success': True,
                    'processed_at': datetime.now().isoformat()
                }
            else:
                # é™çº§å¤„ç†ï¼šåŸºç¡€å›¾åƒä¿¡æ¯
                return await self._basic_image_analysis(processed_image, image_item)
                
        except Exception as e:
            logger.error(f"å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return {
                'type': 'image',
                'filename': image_item.get('filename', 'æœªçŸ¥å›¾åƒ'),
                'analysis': f"å›¾åƒåˆ†æå¤±è´¥: {str(e)}",
                'success': False,
                'error': str(e)
            }
    
    def _build_image_analysis_prompt(self, user_message: str) -> str:
        """æ„å»ºå›¾åƒåˆ†ææç¤ºè¯"""
        base_prompt = "è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾åƒï¼ŒåŒ…æ‹¬ï¼š"
        
        # æ ¹æ®ç”¨æˆ·æ¶ˆæ¯è°ƒæ•´åˆ†æé‡ç‚¹
        if any(word in user_message.lower() for word in ['æ–‡å­—', 'æ–‡æœ¬', 'text', 'ocr']):
            base_prompt += "\n- è¯†åˆ«å›¾åƒä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹"
        
        if any(word in user_message.lower() for word in ['å¯¹è±¡', 'ç‰©ä½“', 'object', 'è¯†åˆ«']):
            base_prompt += "\n- è¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡å’Œç‰©ä½“"
        
        if any(word in user_message.lower() for word in ['åœºæ™¯', 'scene', 'ç¯å¢ƒ']):
            base_prompt += "\n- æè¿°å›¾åƒçš„åœºæ™¯å’Œç¯å¢ƒ"
        
        if any(word in user_message.lower() for word in ['é¢œè‰²', 'color', 'è‰²å½©']):
            base_prompt += "\n- åˆ†æå›¾åƒçš„è‰²å½©æ„æˆ"
        
        if any(word in user_message.lower() for word in ['æƒ…æ„Ÿ', 'emotion', 'æ„Ÿè§‰']):
            base_prompt += "\n- åˆ†æå›¾åƒä¼ è¾¾çš„æƒ…æ„Ÿæˆ–æ°›å›´"
        
        # é»˜è®¤åˆ†æå†…å®¹
        base_prompt += """
- å›¾åƒçš„ä¸»è¦å†…å®¹å’Œä¸»é¢˜
- å›¾åƒä¸­çš„é‡è¦ç»†èŠ‚
- å›¾åƒçš„æ•´ä½“è´¨é‡å’Œç‰¹ç‚¹
- ä»»ä½•å€¼å¾—æ³¨æ„çš„ç‰¹æ®Šå…ƒç´ 

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå†…å®¹è¦è¯¦ç»†ä¸”å‡†ç¡®ã€‚"""
        
        if user_message and user_message.strip():
            base_prompt += f"\n\nç”¨æˆ·ç‰¹åˆ«è¯¢é—®: {user_message}"
        
        return base_prompt
    
    async def _basic_image_analysis(self, image_data: bytes, image_item: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºç¡€å›¾åƒåˆ†æï¼ˆå½“å¤šæ¨¡æ€æ¨¡å‹ä¸å¯ç”¨æ—¶ï¼‰"""
        try:
            # ä½¿ç”¨PILè·å–åŸºç¡€ä¿¡æ¯
            image = Image.open(io.BytesIO(image_data))
            
            analysis = f"""å›¾åƒåŸºç¡€ä¿¡æ¯ï¼š
- å°ºå¯¸: {image.size[0]} x {image.size[1]} åƒç´ 
- æ¨¡å¼: {image.mode}
- æ ¼å¼: {image.format or 'æœªçŸ¥'}
- æ–‡ä»¶å¤§å°: {len(image_data) / 1024:.1f} KB

æ³¨æ„ï¼šç”±äºå¤šæ¨¡æ€æ¨¡å‹æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•æä¾›è¯¦ç»†çš„å†…å®¹åˆ†æã€‚è¯·ç¡®ä¿å¤šæ¨¡æ€æ¨¡å‹æœåŠ¡æ­£å¸¸è¿è¡Œä»¥è·å¾—å®Œæ•´çš„å›¾åƒåˆ†æåŠŸèƒ½ã€‚"""
            
            return {
                'type': 'image',
                'filename': image_item.get('filename', 'æœªçŸ¥å›¾åƒ'),
                'analysis': analysis,
                'success': True,
                'basic_info': {
                    'width': image.size[0],
                    'height': image.size[1],
                    'mode': image.mode,
                    'format': image.format,
                    'size_kb': len(image_data) / 1024
                }
            }
            
        except Exception as e:
            logger.error(f"åŸºç¡€å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return {
                'type': 'image',
                'filename': image_item.get('filename', 'æœªçŸ¥å›¾åƒ'),
                'analysis': f"æ— æ³•åˆ†æå›¾åƒ: {str(e)}",
                'success': False,
                'error': str(e)
            }
    
    async def _analyze_video(
        self,
        video_item: Dict[str, Any],
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """åˆ†æè§†é¢‘å†…å®¹ï¼ˆæœªæ¥å®ç°ï¼‰"""
        self.video_processed += 1
        
        return {
            'type': 'video',
            'filename': video_item.get('filename', 'æœªçŸ¥è§†é¢‘'),
            'analysis': 'è§†é¢‘åˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ã€‚',
            'success': False,
            'note': 'è§†é¢‘åˆ†æåŠŸèƒ½å°†åœ¨åç»­ç‰ˆæœ¬ä¸­æä¾›'
        }
    
    async def _analyze_audio(
        self,
        audio_item: Dict[str, Any],
        user_message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """åˆ†æéŸ³é¢‘å†…å®¹ï¼ˆæœªæ¥å®ç°ï¼‰"""
        self.audio_processed += 1
        
        return {
            'type': 'audio',
            'filename': audio_item.get('filename', 'æœªçŸ¥éŸ³é¢‘'),
            'analysis': 'éŸ³é¢‘åˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ã€‚',
            'success': False,
            'note': 'éŸ³é¢‘åˆ†æåŠŸèƒ½å°†åœ¨åç»­ç‰ˆæœ¬ä¸­æä¾›'
        }
    
    async def _generate_multimodal_response(
        self,
        user_message: str,
        analysis_results: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """ç”Ÿæˆå¤šæ¨¡æ€åˆ†æçš„ç»¼åˆå›ç­”"""
        try:
            if not analysis_results:
                return "æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•å¤šåª’ä½“å†…å®¹ã€‚"
            
            # ç»Ÿè®¡åˆ†æç»“æœ
            successful_analyses = [r for r in analysis_results if r.get('success', False)]
            failed_analyses = [r for r in analysis_results if not r.get('success', False)]
            
            response_parts = []
            
            # æ·»åŠ æˆåŠŸåˆ†æçš„ç»“æœ
            if successful_analyses:
                response_parts.append("ğŸ“¸ å¤šåª’ä½“å†…å®¹åˆ†æç»“æœï¼š\n")
                
                for i, result in enumerate(successful_analyses, 1):
                    filename = result.get('filename', f'æ–‡ä»¶{i}')
                    analysis = result.get('analysis', 'æ— åˆ†æç»“æœ')
                    media_type = result.get('type', 'æœªçŸ¥ç±»å‹')
                    
                    response_parts.append(f"**{i}. {filename} ({media_type})**")
                    response_parts.append(analysis)
                    response_parts.append("")  # ç©ºè¡Œåˆ†éš”
            
            # æ·»åŠ å¤±è´¥åˆ†æçš„ä¿¡æ¯
            if failed_analyses:
                response_parts.append("âŒ ä»¥ä¸‹æ–‡ä»¶åˆ†æå¤±è´¥ï¼š")
                for result in failed_analyses:
                    filename = result.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                    error = result.get('error', result.get('analysis', 'æœªçŸ¥é”™è¯¯'))
                    response_parts.append(f"- {filename}: {error}")
                response_parts.append("")
            
            # æ·»åŠ æ€»ç»“
            if successful_analyses:
                total_files = len(analysis_results)
                successful_count = len(successful_analyses)
                response_parts.append(f"ğŸ“Š åˆ†æå®Œæˆï¼šæˆåŠŸå¤„ç† {successful_count}/{total_files} ä¸ªæ–‡ä»¶")
                
                if user_message and user_message.strip():
                    response_parts.append(f"\né’ˆå¯¹æ‚¨çš„é—®é¢˜ã€Œ{user_message}ã€ï¼Œä»¥ä¸Šæ˜¯æˆ‘å¯¹ä¸Šä¼ å†…å®¹çš„è¯¦ç»†åˆ†æã€‚å¦‚éœ€æ›´å¤šä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£çš„å…·ä½“æ–¹é¢ã€‚")
            
            return "\n".join(response_parts)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤šæ¨¡æ€å›ç­”å¤±è´¥: {str(e)}")
            return "åˆ†æå®Œæˆï¼Œä½†ç”Ÿæˆå›ç­”æ—¶é‡åˆ°é—®é¢˜ã€‚è¯·æŸ¥çœ‹ä¸Šè¿°åˆ†æç»“æœã€‚"
    
    async def analyze_image_direct(
        self,
        image_data: Union[str, bytes],
        prompt: str = "è¯·æè¿°è¿™å¼ å›¾ç‰‡"
    ) -> str:
        """
        ç›´æ¥å›¾åƒåˆ†ææ¥å£ï¼ˆä¾›å…¶ä»–ç»„ä»¶è°ƒç”¨ï¼‰
        
        Args:
            image_data: å›¾åƒæ•°æ®ï¼ˆæ–‡ä»¶è·¯å¾„æˆ–å­—èŠ‚æ•°æ®ï¼‰
            prompt: åˆ†ææç¤ºè¯
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            if not self.multimodal_service:
                await self.initialize_services()
            
            if isinstance(image_data, str):
                with open(image_data, 'rb') as f:
                    image_bytes = f.read()
            else:
                image_bytes = image_data
            
            # å¤„ç†å›¾åƒ
            processed_image = await self.media_processor.process_image(
                image_bytes, self.max_image_size
            )
            
            # åˆ†æå›¾åƒ
            if self.multimodal_service:
                result = await self.multimodal_service.analyze_image(
                    image_data=processed_image,
                    prompt=prompt
                )
                return result
            else:
                return "å¤šæ¨¡æ€æ¨¡å‹æœåŠ¡ä¸å¯ç”¨"
                
        except Exception as e:
            logger.error(f"ç›´æ¥å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return f"å›¾åƒåˆ†æå¤±è´¥: {str(e)}"
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'agent_name': self.name,
            'images_processed': self.image_processed,
            'videos_processed': self.video_processed,
            'audios_processed': self.audio_processed,
            'total_processed': self.image_processed + self.video_processed + self.audio_processed,
            'supported_formats': self.supported_formats,
            'max_file_size_mb': self.max_file_size / 1024 / 1024,
            'max_image_size': self.max_image_size
        }
