#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
è‡ªåŠ¨ä»ModelScopeä¸‹è½½åµŒå…¥æ¨¡å‹å’Œé‡æ’æ¨¡å‹
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from modelscope import snapshot_download
import torch

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self, cache_dir: str = "./models", force_download: bool = False):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.force_download = force_download
        
        # æ¨¡å‹é…ç½®
        self.models_config = {
            "embedding": {
                "model_id": "Qwen/Qwen3-0.6B",
                "description": "é€šä¹‰åƒé—®3-0.6BåµŒå…¥æ¨¡å‹",
                "required_files": [
                    "config.json",
                    "pytorch_model.bin",
                    "tokenizer.json",
                    "tokenizer_config.json",
                    "vocab.txt"
                ]
            },
            "rerank": {
                "model_id": "Qwen/Qwen3-Reranker-0.6B", 
                "description": "é€šä¹‰åƒé—®3-Reranker-0.6Bé‡æ’æ¨¡å‹",
                "required_files": [
                    "config.json",
                    "pytorch_model.bin",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ]
            }
        }
    
    def check_model_exists(self, model_type: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨"""
        try:
            model_config = self.models_config.get(model_type)
            if not model_config:
                return False
            
            model_id = model_config["model_id"]
            model_path = self.cache_dir / model_id.replace("/", "--")
            
            if not model_path.exists():
                return False
            
            # æ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            required_files = model_config.get("required_files", [])
            for file_name in required_files:
                if not (model_path / file_name).exists():
                    logger.warning(f"æ¨¡å‹ {model_type} ç¼ºå°‘æ–‡ä»¶: {file_name}")
                    return False
            
            logger.info(f"æ¨¡å‹ {model_type} å·²å­˜åœ¨: {model_path}")
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ¨¡å‹ {model_type} æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def download_model(self, model_type: str) -> Optional[str]:
        """
        ä¸‹è½½æŒ‡å®šæ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ (embedding, rerank)
            
        Returns:
            æ¨¡å‹æœ¬åœ°è·¯å¾„
        """
        try:
            model_config = self.models_config.get(model_type)
            if not model_config:
                logger.error(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
                return None
            
            model_id = model_config["model_id"]
            description = model_config["description"]
            
            logger.info(f"å¼€å§‹ä¸‹è½½ {description} ({model_id})")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½
            if not self.force_download and self.check_model_exists(model_type):
                logger.info(f"æ¨¡å‹ {model_type} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                return str(self.cache_dir / model_id.replace("/", "--"))
            
            # ä¸‹è½½æ¨¡å‹
            model_path = snapshot_download(
                model_id=model_id,
                cache_dir=str(self.cache_dir),
                revision="master"
            )
            
            logger.info(f"æ¨¡å‹ {description} ä¸‹è½½å®Œæˆ: {model_path}")
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
            if self.verify_model(model_type, model_path):
                logger.info(f"æ¨¡å‹ {model_type} éªŒè¯æˆåŠŸ")
                return model_path
            else:
                logger.error(f"æ¨¡å‹ {model_type} éªŒè¯å¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"ä¸‹è½½æ¨¡å‹ {model_type} å¤±è´¥: {str(e)}")
            return None
    
    def verify_model(self, model_type: str, model_path: str) -> bool:
        """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            model_config = self.models_config.get(model_type)
            if not model_config:
                return False
            
            model_path = Path(model_path)
            required_files = model_config.get("required_files", [])
            
            # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
            for file_name in required_files:
                file_path = model_path / file_name
                if not file_path.exists():
                    logger.error(f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {file_path}")
                    return False
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                if file_path.stat().st_size == 0:
                    logger.error(f"æ–‡ä»¶ä¸ºç©º: {file_path}")
                    return False
            
            # å°è¯•åŠ è½½æ¨¡å‹é…ç½®
            config_path = model_path / "config.json"
            if config_path.exists():
                import json
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    logger.info(f"æ¨¡å‹é…ç½®: {config.get('model_type', 'unknown')}")
            
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯æ¨¡å‹å¤±è´¥: {str(e)}")
            return False
    
    def download_all_models(self) -> Dict[str, Optional[str]]:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        results = {}
        
        for model_type in self.models_config.keys():
            logger.info(f"\n{'='*50}")
            logger.info(f"å¤„ç†æ¨¡å‹: {model_type}")
            logger.info(f"{'='*50}")
            
            model_path = self.download_model(model_type)
            results[model_type] = model_path
            
            if model_path:
                logger.info(f"âœ… {model_type} æ¨¡å‹ä¸‹è½½æˆåŠŸ")
            else:
                logger.error(f"âŒ {model_type} æ¨¡å‹ä¸‹è½½å¤±è´¥")
        
        return results
    
    def get_model_info(self) -> Dict[str, Dict]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {}
        
        for model_type, config in self.models_config.items():
            model_id = config["model_id"]
            model_path = self.cache_dir / model_id.replace("/", "--")
            
            info[model_type] = {
                "model_id": model_id,
                "description": config["description"],
                "local_path": str(model_path),
                "exists": self.check_model_exists(model_type),
                "size_mb": self._get_directory_size(model_path) if model_path.exists() else 0
            }
        
        return info
    
    def _get_directory_size(self, path: Path) -> float:
        """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
        try:
            total_size = 0
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
            return total_size / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        except Exception:
            return 0
    
    def cleanup_incomplete_downloads(self):
        """æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è½½"""
        try:
            for model_type in self.models_config.keys():
                if not self.check_model_exists(model_type):
                    model_id = self.models_config[model_type]["model_id"]
                    model_path = self.cache_dir / model_id.replace("/", "--")
                    
                    if model_path.exists():
                        logger.info(f"æ¸…ç†ä¸å®Œæ•´çš„æ¨¡å‹: {model_path}")
                        import shutil
                        shutil.rmtree(model_path)
                        
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸å®Œæ•´ä¸‹è½½å¤±è´¥: {str(e)}")


def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    logger.info("æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    if python_version < (3, 8):
        logger.error(f"Pythonç‰ˆæœ¬è¿‡ä½: {python_version}, éœ€è¦3.8+")
        return False
    
    # æ£€æŸ¥å¯ç”¨ç£ç›˜ç©ºé—´
    import shutil
    free_space = shutil.disk_usage(".").free / (1024**3)  # GB
    if free_space < 5:
        logger.warning(f"ç£ç›˜ç©ºé—´ä¸è¶³: {free_space:.1f}GB, å»ºè®®è‡³å°‘5GB")
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            logger.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    except ImportError:
        logger.warning("PyTorchæœªå®‰è£…ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    
    # æ£€æŸ¥ModelScope
    try:
        import modelscope
        logger.info(f"ModelScopeç‰ˆæœ¬: {modelscope.__version__}")
    except ImportError:
        logger.error("ModelScopeæœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹")
        return False
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä¸‹è½½æ™ºèƒ½å®¢æœç³»ç»Ÿæ‰€éœ€çš„AIæ¨¡å‹")
    parser.add_argument(
        "--cache-dir", 
        default="./models",
        help="æ¨¡å‹ç¼“å­˜ç›®å½• (é»˜è®¤: ./models)"
    )
    parser.add_argument(
        "--force", 
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½å·²å­˜åœ¨çš„æ¨¡å‹"
    )
    parser.add_argument(
        "--model-type",
        choices=["embedding", "rerank", "all"],
        default="all",
        help="è¦ä¸‹è½½çš„æ¨¡å‹ç±»å‹ (é»˜è®¤: all)"
    )
    parser.add_argument(
        "--info",
        action="store_true",
        help="ä»…æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼Œä¸ä¸‹è½½"
    )
    parser.add_argument(
        "--cleanup",
        action="store_true",
        help="æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è½½"
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="éªŒè¯å·²ä¸‹è½½çš„æ¨¡å‹"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
    if not check_system_requirements():
        logger.error("ç³»ç»Ÿè¦æ±‚æ£€æŸ¥å¤±è´¥")
        sys.exit(1)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ModelDownloader(
        cache_dir=args.cache_dir,
        force_download=args.force
    )
    
    try:
        if args.cleanup:
            logger.info("æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è½½...")
            downloader.cleanup_incomplete_downloads()
            return
        
        if args.info:
            logger.info("è·å–æ¨¡å‹ä¿¡æ¯...")
            model_info = downloader.get_model_info()
            
            print("\n" + "="*60)
            print("æ¨¡å‹ä¿¡æ¯")
            print("="*60)
            
            for model_type, info in model_info.items():
                print(f"\n{model_type.upper()} æ¨¡å‹:")
                print(f"  ID: {info['model_id']}")
                print(f"  æè¿°: {info['description']}")
                print(f"  æœ¬åœ°è·¯å¾„: {info['local_path']}")
                print(f"  å·²ä¸‹è½½: {'âœ…' if info['exists'] else 'âŒ'}")
                if info['exists']:
                    print(f"  å¤§å°: {info['size_mb']:.1f} MB")
            
            return
        
        if args.verify:
            logger.info("éªŒè¯å·²ä¸‹è½½çš„æ¨¡å‹...")
            for model_type in downloader.models_config.keys():
                if downloader.check_model_exists(model_type):
                    logger.info(f"âœ… {model_type} æ¨¡å‹éªŒè¯é€šè¿‡")
                else:
                    logger.error(f"âŒ {model_type} æ¨¡å‹éªŒè¯å¤±è´¥")
            return
        
        # ä¸‹è½½æ¨¡å‹
        if args.model_type == "all":
            logger.info("å¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
            results = downloader.download_all_models()
        else:
            logger.info(f"å¼€å§‹ä¸‹è½½ {args.model_type} æ¨¡å‹...")
            model_path = downloader.download_model(args.model_type)
            results = {args.model_type: model_path}
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        print("\n" + "="*60)
        print("ä¸‹è½½ç»“æœæ‘˜è¦")
        print("="*60)
        
        success_count = 0
        for model_type, model_path in results.items():
            if model_path:
                print(f"âœ… {model_type}: {model_path}")
                success_count += 1
            else:
                print(f"âŒ {model_type}: ä¸‹è½½å¤±è´¥")
        
        print(f"\næˆåŠŸä¸‹è½½: {success_count}/{len(results)} ä¸ªæ¨¡å‹")
        
        if success_count == len(results):
            print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            print("ç°åœ¨å¯ä»¥å¯åŠ¨æ™ºèƒ½å®¢æœç³»ç»Ÿäº†ã€‚")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ—¥å¿—ä¿¡æ¯ã€‚")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
