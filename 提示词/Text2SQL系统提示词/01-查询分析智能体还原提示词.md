# 查询分析智能体还原提示词

## 🎯 智能体概述

查询分析智能体（Query Analyzer Agent）是Text2SQL系统的第一个核心组件，负责深度理解用户的自然语言查询，识别查询意图，提取相关实体，并为后续的SQL生成提供结构化的分析结果。

## 🧠 核心功能

### 1. 自然语言意图理解
- **查询类型识别**: 区分查询、统计、排序、筛选等不同操作类型
- **业务场景理解**: 理解用户在特定业务场景下的查询需求
- **复杂度评估**: 评估查询的复杂程度和所需的处理步骤
- **歧义消解**: 处理自然语言中的歧义表达

### 2. 数据实体识别
- **业务实体提取**: 识别查询中涉及的业务对象（客户、订单、产品等）
- **属性字段映射**: 将自然语言描述映射到具体的数据库字段
- **数值条件识别**: 识别查询中的数值范围、比较条件等
- **时间条件解析**: 解析时间相关的查询条件

### 3. 表关系分析
- **主表确定**: 确定查询的主要数据表
- **关联表识别**: 识别需要关联的其他表
- **连接条件分析**: 分析表之间的连接关系和条件
- **数据路径规划**: 规划从查询意图到数据获取的路径

## 🔧 技术实现

### 智能体定义

```python
class QueryAnalyzerAgent:
    """
    查询分析智能体实现
    
    功能:
    1. 接收用户自然语言查询
    2. 分析查询意图和实体
    3. 映射到数据库结构
    4. 输出结构化分析结果
    """
    
    def __init__(self, db_schema: str, model_client):
        self.db_schema = db_schema
        self.model_client = model_client
        self.system_message = self._build_system_message()
    
    def _build_system_message(self) -> str:
        """构建系统提示词"""
        return f"""
你是一个专业的数据库查询分析专家。你的任务是深度分析用户的自然语言查询，理解其意图并识别相关的数据库实体。

## 核心职责：
1. **意图识别**: 准确理解用户想要执行的操作类型
2. **实体提取**: 识别查询中涉及的所有业务实体
3. **字段映射**: 将业务概念映射到具体的数据库字段
4. **关系分析**: 分析涉及的表之间的关联关系
5. **条件解析**: 解析查询中的筛选和排序条件

## 分析框架：

### 1. 查询意图分类
- **数据查询**: 获取特定数据记录
- **统计分析**: 计算总数、平均值、最大值等
- **排序展示**: 按某种规则排序显示数据
- **条件筛选**: 根据条件过滤数据
- **关联查询**: 跨表关联获取数据
- **时间分析**: 基于时间维度的数据分析

### 2. 实体识别模式
- **主体实体**: 查询的核心对象（如客户、订单、产品）
- **属性实体**: 实体的具体属性（如姓名、价格、日期）
- **关系实体**: 实体间的关联关系（如客户的订单、订单的商品）
- **条件实体**: 筛选和限制条件（如时间范围、数值区间）

### 3. 数据库映射规则
- **表名映射**: 业务实体到数据库表的映射
- **字段映射**: 属性描述到具体字段的映射
- **关系映射**: 业务关系到外键关联的映射
- **条件映射**: 自然语言条件到SQL条件的映射

## 数据库结构信息：
{self.db_schema}

## 分析输出格式：
请按照以下结构化格式输出分析结果：

```json
{{
  "query_intent": {{
    "type": "查询类型（query/statistics/sort/filter/join/time_analysis）",
    "description": "查询意图的详细描述",
    "complexity": "复杂度评级（simple/medium/complex）"
  }},
  "entities": {{
    "primary_entity": "主要查询实体",
    "secondary_entities": ["次要相关实体列表"],
    "attributes": ["涉及的属性字段列表"],
    "conditions": ["筛选条件列表"]
  }},
  "table_mapping": {{
    "primary_table": "主要数据表",
    "related_tables": ["相关表列表"],
    "join_conditions": ["表连接条件"],
    "required_fields": ["需要的字段列表"]
  }},
  "query_structure": {{
    "select_fields": ["需要选择的字段"],
    "where_conditions": ["WHERE条件"],
    "join_requirements": ["JOIN需求"],
    "group_by_fields": ["分组字段（如果需要）"],
    "order_by_fields": ["排序字段（如果需要）"],
    "limit_requirements": "限制条件（如果需要）"
  }},
  "analysis_confidence": "分析置信度（0-1）",
  "potential_issues": ["可能的问题或歧义"]
}}
```

## 分析示例：

**用户查询**: "查找购买金额最高的前10个客户"

**分析结果**:
```json
{{
  "query_intent": {{
    "type": "statistics",
    "description": "统计客户购买金额并按金额降序排列，获取前10名",
    "complexity": "medium"
  }},
  "entities": {{
    "primary_entity": "客户",
    "secondary_entities": ["订单", "购买金额"],
    "attributes": ["客户信息", "购买总金额"],
    "conditions": ["按金额排序", "限制前10名"]
  }},
  "table_mapping": {{
    "primary_table": "Customer",
    "related_tables": ["Invoice"],
    "join_conditions": ["Customer.CustomerId = Invoice.CustomerId"],
    "required_fields": ["Customer.FirstName", "Customer.LastName", "Invoice.Total"]
  }},
  "query_structure": {{
    "select_fields": ["Customer.FirstName", "Customer.LastName", "SUM(Invoice.Total) as TotalAmount"],
    "where_conditions": [],
    "join_requirements": ["INNER JOIN Invoice ON Customer.CustomerId = Invoice.CustomerId"],
    "group_by_fields": ["Customer.CustomerId", "Customer.FirstName", "Customer.LastName"],
    "order_by_fields": ["TotalAmount DESC"],
    "limit_requirements": "LIMIT 10"
  }},
  "analysis_confidence": 0.95,
  "potential_issues": []
}}
```

## 特殊处理规则：

### 1. 时间表达处理
- "最近一个月" → 当前日期前30天
- "今年" → 当前年份
- "上季度" → 上一个季度的时间范围
- "去年同期" → 去年相同时间段

### 2. 数值表达处理
- "最高的" → ORDER BY DESC LIMIT
- "超过100" → WHERE field > 100
- "前10名" → ORDER BY DESC LIMIT 10
- "平均" → AVG()函数

### 3. 模糊表达处理
- "相关的" → 通过外键关联
- "类似的" → LIKE模糊匹配
- "大约" → 范围查询
- "经常" → 频次统计

### 4. 业务术语映射
- "客户" → Customer表
- "订单" → Invoice表
- "商品" → Track表
- "销售额" → Invoice.Total
- "购买记录" → InvoiceLine表

请仔细分析用户查询，提供准确、详细的结构化分析结果。
"""
    
    async def analyze_query(self, user_query: str) -> Dict[str, Any]:
        """分析用户查询"""
        try:
            # 构建分析提示
            analysis_prompt = f"""
请分析以下用户查询：

用户查询: "{user_query}"

请按照系统消息中定义的格式，提供详细的结构化分析结果。
"""
            
            # 调用AI模型进行分析
            response = await self.model_client.create(
                messages=[
                    {"role": "system", "content": self.system_message},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.1,  # 低温度确保分析的一致性
                max_tokens=2000
            )
            
            # 解析响应
            analysis_result = self._parse_analysis_response(response.choices[0].message.content)
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"查询分析失败: {str(e)}")
            return self._create_error_response(str(e))
    
    def _parse_analysis_response(self, response_content: str) -> Dict[str, Any]:
        """解析AI响应内容"""
        try:
            # 提取JSON部分
            json_start = response_content.find('{')
            json_end = response_content.rfind('}') + 1
            
            if json_start != -1 and json_end != -1:
                json_content = response_content[json_start:json_end]
                analysis_result = json.loads(json_content)
                return analysis_result
            else:
                # 如果没有找到JSON格式，返回文本分析
                return {
                    "analysis_text": response_content,
                    "structured_analysis": False
                }
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON解析失败: {str(e)}")
            return {
                "analysis_text": response_content,
                "structured_analysis": False,
                "parse_error": str(e)
            }
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """创建错误响应"""
        return {
            "error": True,
            "message": f"查询分析失败: {error_message}",
            "query_intent": {
                "type": "unknown",
                "description": "无法分析查询意图",
                "complexity": "unknown"
            }
        }
```

### 智能体注册和配置

```python
def _create_query_analyzer_agent(self) -> AssistantAgent:
    """
    创建查询分析智能体
    
    配置要点:
    1. 设置专业的系统提示词
    2. 配置合适的模型参数
    3. 设置输出格式要求
    4. 配置错误处理机制
    """
    
    # 构建详细的系统提示词
    system_message = f"""
你是Text2SQL系统中的查询分析专家。你的核心任务是深度理解用户的自然语言查询，并提供结构化的分析结果。

## 你的专业能力：
1. **语言理解**: 准确理解各种自然语言表达方式
2. **意图识别**: 识别用户的真实查询意图
3. **实体抽取**: 提取查询中的关键业务实体
4. **结构映射**: 将自然语言映射到数据库结构
5. **逻辑分析**: 分析查询的逻辑关系和执行步骤

## 工作流程：
1. **接收查询**: 获取用户的自然语言查询
2. **意图分析**: 理解用户想要实现的目标
3. **实体识别**: 识别查询涉及的数据实体
4. **结构映射**: 映射到具体的数据库表和字段
5. **输出分析**: 提供结构化的分析结果

## 数据库结构：
{self.db_schema}

## 输出要求：
- 提供清晰的分析思路
- 输出结构化的分析结果
- 标识可能的歧义和问题
- 为后续SQL生成提供充分信息

请始终保持专业、准确、详细的分析风格。
"""
    
    # 创建智能体实例
    agent = AssistantAgent(
        name="query_analyzer",
        model_client=self.model_client,
        system_message=system_message,
        description="专业的查询分析智能体，负责理解自然语言查询并提供结构化分析"
    )
    
    return agent
```

## 📊 分析能力矩阵

### 支持的查询类型

| 查询类型 | 描述 | 示例 | 复杂度 |
|---------|------|------|--------|
| 简单查询 | 单表数据获取 | "显示所有客户" | Simple |
| 条件查询 | 带筛选条件的查询 | "显示来自美国的客户" | Simple |
| 排序查询 | 带排序的数据查询 | "按姓名排序显示客户" | Simple |
| 聚合查询 | 统计分析类查询 | "统计每个国家的客户数量" | Medium |
| 关联查询 | 多表连接查询 | "显示客户及其订单信息" | Medium |
| 复杂统计 | 复杂的统计分析 | "分析每月销售趋势" | Complex |
| 嵌套查询 | 包含子查询的复杂查询 | "找出购买最多的客户" | Complex |

### 实体识别能力

| 实体类型 | 识别能力 | 映射准确度 | 示例 |
|---------|----------|------------|------|
| 客户实体 | ✅ 高 | 95% | Customer表相关 |
| 订单实体 | ✅ 高 | 95% | Invoice表相关 |
| 产品实体 | ✅ 高 | 90% | Track/Album表相关 |
| 时间实体 | ✅ 中 | 85% | 日期时间字段 |
| 数值实体 | ✅ 中 | 80% | 价格、数量等 |
| 关系实体 | ✅ 中 | 75% | 表间关联关系 |

### 条件解析能力

| 条件类型 | 支持程度 | 准确率 | 示例 |
|---------|----------|--------|------|
| 等值条件 | ✅ 完全支持 | 95% | "国家是美国" |
| 范围条件 | ✅ 完全支持 | 90% | "价格在100-500之间" |
| 模糊条件 | ✅ 部分支持 | 80% | "姓名包含Smith" |
| 时间条件 | ✅ 部分支持 | 75% | "最近一个月" |
| 复合条件 | ⚠️ 有限支持 | 70% | "美国客户且购买超过1000" |
| 否定条件 | ⚠️ 有限支持 | 65% | "不是来自美国的客户" |

## 🔍 质量保证机制

### 1. 分析验证
```python
def validate_analysis_result(self, analysis: Dict[str, Any]) -> bool:
    """
    验证分析结果的完整性和正确性
    
    验证项目:
    1. 必要字段完整性
    2. 表名和字段名有效性
    3. 查询逻辑合理性
    4. 数据类型匹配性
    """
    required_fields = [
        'query_intent', 'entities', 'table_mapping', 'query_structure'
    ]
    
    # 检查必要字段
    for field in required_fields:
        if field not in analysis:
            return False
    
    # 验证表名有效性
    primary_table = analysis.get('table_mapping', {}).get('primary_table')
    if primary_table and not self._is_valid_table(primary_table):
        return False
    
    # 验证字段名有效性
    required_fields = analysis.get('query_structure', {}).get('required_fields', [])
    for field in required_fields:
        if not self._is_valid_field(field):
            return False
    
    return True

def _is_valid_table(self, table_name: str) -> bool:
    """验证表名是否存在于数据库结构中"""
    valid_tables = ['Customer', 'Invoice', 'InvoiceLine', 'Track', 'Album', 'Artist', 'Genre', 'MediaType', 'Playlist', 'PlaylistTrack', 'Employee']
    return table_name in valid_tables

def _is_valid_field(self, field_name: str) -> bool:
    """验证字段名是否有效"""
    # 简化验证，实际应该检查具体表的字段
    return '.' in field_name or field_name.upper() in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN']
```

### 2. 置信度评估
```python
def calculate_confidence(self, analysis: Dict[str, Any], user_query: str) -> float:
    """
    计算分析结果的置信度
    
    评估因素:
    1. 查询明确性 (40%)
    2. 实体识别准确性 (30%)
    3. 表映射正确性 (20%)
    4. 逻辑一致性 (10%)
    """
    confidence_score = 0.0
    
    # 查询明确性评估
    query_clarity = self._assess_query_clarity(user_query)
    confidence_score += query_clarity * 0.4
    
    # 实体识别准确性
    entity_accuracy = self._assess_entity_accuracy(analysis)
    confidence_score += entity_accuracy * 0.3
    
    # 表映射正确性
    mapping_correctness = self._assess_mapping_correctness(analysis)
    confidence_score += mapping_correctness * 0.2
    
    # 逻辑一致性
    logic_consistency = self._assess_logic_consistency(analysis)
    confidence_score += logic_consistency * 0.1
    
    return min(confidence_score, 1.0)
```

### 3. 错误处理和恢复
```python
def handle_analysis_error(self, error: Exception, user_query: str) -> Dict[str, Any]:
    """
    处理分析过程中的错误
    
    错误类型:
    1. 模型调用失败
    2. 响应解析错误
    3. 结构验证失败
    4. 超时错误
    """
    error_type = type(error).__name__
    
    if error_type == 'TimeoutError':
        return self._create_timeout_fallback(user_query)
    elif error_type == 'JSONDecodeError':
        return self._create_parsing_fallback(user_query)
    elif error_type == 'ValidationError':
        return self._create_validation_fallback(user_query)
    else:
        return self._create_generic_fallback(user_query, str(error))

def _create_timeout_fallback(self, user_query: str) -> Dict[str, Any]:
    """创建超时情况下的备用分析"""
    return {
        "query_intent": {
            "type": "query",
            "description": f"基于查询内容的基础分析: {user_query}",
            "complexity": "unknown"
        },
        "entities": {
            "primary_entity": "未确定",
            "secondary_entities": [],
            "attributes": [],
            "conditions": []
        },
        "table_mapping": {
            "primary_table": "Customer",  # 默认主表
            "related_tables": [],
            "join_conditions": [],
            "required_fields": ["*"]
        },
        "analysis_confidence": 0.3,
        "fallback_reason": "分析超时，使用备用方案"
    }
```

## 🚀 性能优化

### 1. 缓存机制
```python
class QueryAnalysisCache:
    """
    查询分析结果缓存
    
    优化策略:
    1. 相似查询缓存
    2. 实体映射缓存
    3. 模式识别缓存
    """
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.max_size = max_size
        self.access_count = {}
    
    def get_cached_analysis(self, query: str) -> Optional[Dict[str, Any]]:
        """获取缓存的分析结果"""
        query_hash = self._hash_query(query)
        
        if query_hash in self.cache:
            self.access_count[query_hash] = self.access_count.get(query_hash, 0) + 1
            return self.cache[query_hash]
        
        # 检查相似查询
        similar_query = self._find_similar_query(query)
        if similar_query:
            return self.cache[similar_query]
        
        return None
    
    def cache_analysis(self, query: str, analysis: Dict[str, Any]):
        """缓存分析结果"""
        if len(self.cache) >= self.max_size:
            self._evict_least_used()
        
        query_hash = self._hash_query(query)
        self.cache[query_hash] = analysis
        self.access_count[query_hash] = 1
```

### 2. 并行处理
```python
async def parallel_analysis(self, user_query: str) -> Dict[str, Any]:
    """
    并行执行多个分析任务
    
    并行任务:
    1. 意图识别
    2. 实体提取
    3. 表映射
    4. 条件解析
    """
    tasks = [
        self._analyze_intent(user_query),
        self._extract_entities(user_query),
        self._map_tables(user_query),
        self._parse_conditions(user_query)
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 合并结果
    final_analysis = self._merge_analysis_results(results)
    
    return final_analysis
```

---

**总结**: 查询分析智能体是Text2SQL系统的核心入口，负责将自然语言查询转换为结构化的分析结果。通过深度的意图理解、精确的实体识别和智能的表映射，为后续的SQL生成提供高质量的输入。该智能体具备强大的错误处理能力、性能优化机制和质量保证体系，确保分析结果的准确性和可靠性。