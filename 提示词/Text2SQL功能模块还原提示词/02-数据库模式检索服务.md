# 数据库模式检索服务功能还原提示词

## 服务概述

数据库模式检索服务是Text2SQL系统的核心组件，负责管理和检索数据库的结构信息，包括表结构、字段定义、索引信息、外键关系等。该服务为SQL生成提供准确的数据库上下文信息。

## 核心功能

### 1. 数据库连接管理
- 支持多种数据库类型（MySQL、PostgreSQL、SQLite、Snowflake等）
- 动态数据库连接配置和管理
- 连接池优化和连接复用
- 连接状态监控和自动重连

### 2. 模式信息提取
- 自动提取数据库表结构信息
- 获取字段类型、约束和默认值
- 识别主键、外键和索引关系
- 提取表和字段的注释信息

### 3. 向量化存储与检索
- 将数据库模式信息向量化存储
- 基于语义相似度的智能检索
- 支持模糊匹配和同义词识别
- 多维度检索（表名、字段名、注释、数据类型）

### 4. 上下文构建
- 根据查询需求构建相关的数据库上下文
- 智能筛选相关表和字段
- 生成结构化的模式描述
- 优化上下文长度和信息密度

## 技术实现

### 数据库访问抽象层

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
import asyncio

class DBAccess(ABC):
    """数据库访问抽象基类"""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.config = connection_config
        self.connection = None
        self.connection_pool = None
    
    @abstractmethod
    async def connect(self) -> bool:
        """建立数据库连接"""
        pass
    
    @abstractmethod
    async def disconnect(self):
        """关闭数据库连接"""
        pass
    
    @abstractmethod
    async def execute_query(self, sql: str, params: Optional[List] = None) -> List[Dict]:
        """执行SQL查询"""
        pass
    
    @abstractmethod
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """获取表结构信息"""
        pass
    
    @abstractmethod
    async def get_all_tables(self) -> List[str]:
        """获取所有表名"""
        pass
    
    @abstractmethod
    async def get_foreign_keys(self, table_name: str) -> List[Dict]:
        """获取外键关系"""
        pass
```

### MySQL数据库访问实现

```python
import aiomysql
from typing import Dict, List, Optional, Any

class MySQLAccess(DBAccess):
    """MySQL数据库访问实现"""
    
    async def connect(self) -> bool:
        """连接MySQL数据库"""
        try:
            self.connection_pool = await aiomysql.create_pool(
                host=self.config['host'],
                port=self.config.get('port', 3306),
                user=self.config['user'],
                password=self.config['password'],
                db=self.config['database'],
                charset='utf8mb4',
                autocommit=True,
                maxsize=10,
                minsize=1
            )
            return True
        except Exception as e:
            logger.error(f"MySQL连接失败: {e}")
            return False
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """获取MySQL表结构"""
        async with self.connection_pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cursor:
                # 获取表结构
                await cursor.execute("""
                    SELECT 
                        COLUMN_NAME as column_name,
                        DATA_TYPE as data_type,
                        IS_NULLABLE as is_nullable,
                        COLUMN_DEFAULT as column_default,
                        COLUMN_COMMENT as column_comment,
                        COLUMN_KEY as column_key,
                        EXTRA as extra
                    FROM INFORMATION_SCHEMA.COLUMNS 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
                    ORDER BY ORDINAL_POSITION
                """, (self.config['database'], table_name))
                
                columns = await cursor.fetchall()
                
                # 获取表注释
                await cursor.execute("""
                    SELECT TABLE_COMMENT 
                    FROM INFORMATION_SCHEMA.TABLES 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
                """, (self.config['database'], table_name))
                
                table_info = await cursor.fetchone()
                table_comment = table_info['TABLE_COMMENT'] if table_info else ''
                
                return {
                    'table_name': table_name,
                    'table_comment': table_comment,
                    'columns': columns
                }
    
    async def get_all_tables(self) -> List[str]:
        """获取所有表名"""
        async with self.connection_pool.acquire() as conn:
            async with conn.cursor() as cursor:
                await cursor.execute("""
                    SELECT TABLE_NAME 
                    FROM INFORMATION_SCHEMA.TABLES 
                    WHERE TABLE_SCHEMA = %s AND TABLE_TYPE = 'BASE TABLE'
                """, (self.config['database'],))
                
                tables = await cursor.fetchall()
                return [table[0] for table in tables]
    
    async def get_foreign_keys(self, table_name: str) -> List[Dict]:
        """获取外键关系"""
        async with self.connection_pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cursor:
                await cursor.execute("""
                    SELECT 
                        COLUMN_NAME as column_name,
                        REFERENCED_TABLE_NAME as referenced_table,
                        REFERENCED_COLUMN_NAME as referenced_column,
                        CONSTRAINT_NAME as constraint_name
                    FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE 
                    WHERE TABLE_SCHEMA = %s 
                        AND TABLE_NAME = %s 
                        AND REFERENCED_TABLE_NAME IS NOT NULL
                """, (self.config['database'], table_name))
                
                return await cursor.fetchall()
```

### PostgreSQL数据库访问实现

```python
import asyncpg
from typing import Dict, List, Optional, Any

class PostgreSQLAccess(DBAccess):
    """PostgreSQL数据库访问实现"""
    
    async def connect(self) -> bool:
        """连接PostgreSQL数据库"""
        try:
            self.connection_pool = await asyncpg.create_pool(
                host=self.config['host'],
                port=self.config.get('port', 5432),
                user=self.config['user'],
                password=self.config['password'],
                database=self.config['database'],
                min_size=1,
                max_size=10
            )
            return True
        except Exception as e:
            logger.error(f"PostgreSQL连接失败: {e}")
            return False
    
    async def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """获取PostgreSQL表结构"""
        async with self.connection_pool.acquire() as conn:
            # 获取表结构
            columns = await conn.fetch("""
                SELECT 
                    column_name,
                    data_type,
                    is_nullable,
                    column_default,
                    ordinal_position
                FROM information_schema.columns 
                WHERE table_schema = 'public' AND table_name = $1
                ORDER BY ordinal_position
            """, table_name)
            
            # 获取表注释
            table_comment = await conn.fetchval("""
                SELECT obj_description(c.oid) 
                FROM pg_class c 
                JOIN pg_namespace n ON n.oid = c.relnamespace 
                WHERE n.nspname = 'public' AND c.relname = $1
            """, table_name)
            
            # 获取字段注释
            column_comments = await conn.fetch("""
                SELECT 
                    a.attname as column_name,
                    col_description(a.attrelid, a.attnum) as comment
                FROM pg_attribute a
                JOIN pg_class c ON c.oid = a.attrelid
                JOIN pg_namespace n ON n.oid = c.relnamespace
                WHERE n.nspname = 'public' 
                    AND c.relname = $1 
                    AND a.attnum > 0 
                    AND NOT a.attisdropped
            """, table_name)
            
            # 合并注释信息
            comment_dict = {row['column_name']: row['comment'] for row in column_comments}
            
            columns_with_comments = []
            for col in columns:
                col_dict = dict(col)
                col_dict['column_comment'] = comment_dict.get(col['column_name'], '')
                columns_with_comments.append(col_dict)
            
            return {
                'table_name': table_name,
                'table_comment': table_comment or '',
                'columns': columns_with_comments
            }
```

### 模式信息向量化服务

```python
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List, Tuple
import faiss

class SchemaVectorizer:
    """数据库模式向量化服务"""
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()
        self.index = faiss.IndexFlatIP(self.dimension)  # 内积索引
        self.schema_metadata = []  # 存储模式元数据
    
    def vectorize_schema(self, schema_info: Dict[str, Any]) -> np.ndarray:
        """将数据库模式信息向量化"""
        # 构建描述文本
        description_parts = []
        
        # 表名和注释
        table_name = schema_info['table_name']
        table_comment = schema_info.get('table_comment', '')
        description_parts.append(f"表名: {table_name}")
        if table_comment:
            description_parts.append(f"表描述: {table_comment}")
        
        # 字段信息
        for column in schema_info['columns']:
            col_name = column['column_name']
            col_type = column['data_type']
            col_comment = column.get('column_comment', '')
            
            col_desc = f"字段: {col_name} 类型: {col_type}"
            if col_comment:
                col_desc += f" 描述: {col_comment}"
            
            description_parts.append(col_desc)
        
        # 生成向量
        full_description = " ".join(description_parts)
        vector = self.model.encode(full_description)
        
        return vector
    
    def add_schema(self, schema_info: Dict[str, Any]):
        """添加模式信息到向量索引"""
        vector = self.vectorize_schema(schema_info)
        
        # 归一化向量（用于余弦相似度）
        vector = vector / np.linalg.norm(vector)
        
        # 添加到索引
        self.index.add(vector.reshape(1, -1))
        
        # 存储元数据
        self.schema_metadata.append(schema_info)
    
    def search_relevant_schemas(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:
        """搜索相关的数据库模式"""
        # 查询向量化
        query_vector = self.model.encode(query)
        query_vector = query_vector / np.linalg.norm(query_vector)
        
        # 搜索
        scores, indices = self.index.search(query_vector.reshape(1, -1), top_k)
        
        # 返回结果
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.schema_metadata):
                results.append((self.schema_metadata[idx], float(score)))
        
        return results
```

### 模式检索服务主类

```python
class SchemaRetrievalService:
    """数据库模式检索服务"""
    
    def __init__(self, db_access: DBAccess):
        self.db_access = db_access
        self.vectorizer = SchemaVectorizer()
        self.schema_cache = {}  # 模式缓存
        self.last_update = None
    
    async def initialize(self):
        """初始化服务"""
        # 连接数据库
        if not await self.db_access.connect():
            raise Exception("数据库连接失败")
        
        # 加载所有表结构
        await self.load_all_schemas()
    
    async def load_all_schemas(self):
        """加载所有表结构到向量索引"""
        try:
            tables = await self.db_access.get_all_tables()
            
            for table_name in tables:
                schema_info = await self.db_access.get_table_schema(table_name)
                
                # 获取外键信息
                foreign_keys = await self.db_access.get_foreign_keys(table_name)
                schema_info['foreign_keys'] = foreign_keys
                
                # 缓存模式信息
                self.schema_cache[table_name] = schema_info
                
                # 添加到向量索引
                self.vectorizer.add_schema(schema_info)
            
            self.last_update = datetime.now()
            logger.info(f"已加载 {len(tables)} 个表的模式信息")
            
        except Exception as e:
            logger.error(f"加载模式信息失败: {e}")
            raise
    
    async def get_relevant_schemas(self, query: str, max_tables: int = 10) -> List[Dict]:
        """获取与查询相关的数据库模式"""
        # 搜索相关模式
        relevant_schemas = self.vectorizer.search_relevant_schemas(query, max_tables)
        
        # 过滤和排序
        filtered_schemas = []
        for schema_info, score in relevant_schemas:
            if score > 0.3:  # 相似度阈值
                schema_info['relevance_score'] = score
                filtered_schemas.append(schema_info)
        
        return filtered_schemas
    
    async def build_context(self, query: str, max_context_length: int = 4000) -> str:
        """构建数据库上下文"""
        relevant_schemas = await self.get_relevant_schemas(query)
        
        context_parts = []
        current_length = 0
        
        for schema in relevant_schemas:
            schema_text = self._format_schema_text(schema)
            
            if current_length + len(schema_text) > max_context_length:
                break
            
            context_parts.append(schema_text)
            current_length += len(schema_text)
        
        return "\n\n".join(context_parts)
    
    def _format_schema_text(self, schema: Dict[str, Any]) -> str:
        """格式化模式信息为文本"""
        lines = []
        
        # 表信息
        table_name = schema['table_name']
        table_comment = schema.get('table_comment', '')
        
        if table_comment:
            lines.append(f"表 {table_name} ({table_comment}):")
        else:
            lines.append(f"表 {table_name}:")
        
        # 字段信息
        for column in schema['columns']:
            col_name = column['column_name']
            col_type = column['data_type']
            col_comment = column.get('column_comment', '')
            is_nullable = column.get('is_nullable', 'YES')
            column_key = column.get('column_key', '')
            
            # 构建字段描述
            col_desc = f"  - {col_name}: {col_type}"
            
            # 添加约束信息
            constraints = []
            if column_key == 'PRI':
                constraints.append('主键')
            elif column_key == 'UNI':
                constraints.append('唯一')
            
            if is_nullable == 'NO':
                constraints.append('非空')
            
            if constraints:
                col_desc += f" [{', '.join(constraints)}]"
            
            if col_comment:
                col_desc += f" - {col_comment}"
            
            lines.append(col_desc)
        
        # 外键信息
        foreign_keys = schema.get('foreign_keys', [])
        if foreign_keys:
            lines.append("  外键关系:")
            for fk in foreign_keys:
                lines.append(f"    - {fk['column_name']} -> {fk['referenced_table']}.{fk['referenced_column']}")
        
        return "\n".join(lines)
    
    async def refresh_schemas(self):
        """刷新模式信息"""
        # 清空缓存和索引
        self.schema_cache.clear()
        self.vectorizer = SchemaVectorizer()
        
        # 重新加载
        await self.load_all_schemas()
    
    async def get_table_relationships(self, table_names: List[str]) -> Dict[str, List[Dict]]:
        """获取表之间的关系"""
        relationships = {}
        
        for table_name in table_names:
            if table_name in self.schema_cache:
                foreign_keys = self.schema_cache[table_name].get('foreign_keys', [])
                relationships[table_name] = foreign_keys
        
        return relationships
```

## 配置管理

### 数据库配置

```python
from pydantic import BaseModel
from typing import Optional, Dict, Any

class DatabaseConfig(BaseModel):
    """数据库配置模型"""
    type: str  # mysql, postgresql, sqlite, snowflake
    host: str
    port: Optional[int] = None
    user: str
    password: str
    database: str
    schema: Optional[str] = None
    ssl_mode: Optional[str] = None
    connection_timeout: Optional[int] = 30
    pool_size: Optional[int] = 10
    
class SchemaRetrievalConfig(BaseModel):
    """模式检索配置"""
    vector_model: str = "all-MiniLM-L6-v2"
    similarity_threshold: float = 0.3
    max_context_length: int = 4000
    max_tables_per_query: int = 10
    cache_ttl: int = 3600  # 缓存过期时间（秒）
    auto_refresh_interval: int = 86400  # 自动刷新间隔（秒）
```

### 工厂模式实现

```python
class DBAccessFactory:
    """数据库访问工厂"""
    
    @staticmethod
    def create_db_access(config: DatabaseConfig) -> DBAccess:
        """根据配置创建数据库访问对象"""
        if config.type.lower() == 'mysql':
            return MySQLAccess(config.dict())
        elif config.type.lower() == 'postgresql':
            return PostgreSQLAccess(config.dict())
        elif config.type.lower() == 'sqlite':
            return SQLiteAccess(config.dict())
        elif config.type.lower() == 'snowflake':
            return SnowflakeAccess(config.dict())
        else:
            raise ValueError(f"不支持的数据库类型: {config.type}")
```

## API接口

### REST API

```python
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Optional

router = APIRouter()

class SchemaSearchRequest(BaseModel):
    query: str
    max_tables: Optional[int] = 10
    include_relationships: Optional[bool] = True

class SchemaSearchResponse(BaseModel):
    schemas: List[Dict[str, Any]]
    total_count: int
    processing_time: float

@router.post("/search", response_model=SchemaSearchResponse)
async def search_schemas(
    request: SchemaSearchRequest,
    service: SchemaRetrievalService = Depends(get_schema_service)
):
    """搜索相关的数据库模式"""
    start_time = time.time()
    
    try:
        schemas = await service.get_relevant_schemas(
            request.query, 
            request.max_tables
        )
        
        # 添加关系信息
        if request.include_relationships:
            table_names = [schema['table_name'] for schema in schemas]
            relationships = await service.get_table_relationships(table_names)
            
            for schema in schemas:
                table_name = schema['table_name']
                schema['relationships'] = relationships.get(table_name, [])
        
        processing_time = time.time() - start_time
        
        return SchemaSearchResponse(
            schemas=schemas,
            total_count=len(schemas),
            processing_time=processing_time
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/context")
async def build_context(
    query: str,
    max_length: Optional[int] = 4000,
    service: SchemaRetrievalService = Depends(get_schema_service)
):
    """构建数据库上下文"""
    try:
        context = await service.build_context(query, max_length)
        return {"context": context}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/refresh")
async def refresh_schemas(
    service: SchemaRetrievalService = Depends(get_schema_service)
):
    """刷新模式信息"""
    try:
        await service.refresh_schemas()
        return {"message": "模式信息已刷新"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

## 性能优化

### 缓存策略

```python
from functools import lru_cache
import asyncio
from datetime import datetime, timedelta

class SchemaCache:
    """模式缓存管理"""
    
    def __init__(self, ttl: int = 3600):
        self.cache = {}
        self.ttl = ttl
        self.access_times = {}
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        if key in self.cache:
            # 检查是否过期
            if datetime.now() - self.access_times[key] < timedelta(seconds=self.ttl):
                return self.cache[key]
            else:
                # 清理过期缓存
                del self.cache[key]
                del self.access_times[key]
        return None
    
    def set(self, key: str, value: Any):
        """设置缓存"""
        self.cache[key] = value
        self.access_times[key] = datetime.now()
    
    def clear(self):
        """清空缓存"""
        self.cache.clear()
        self.access_times.clear()
```

### 异步批量处理

```python
async def batch_load_schemas(self, table_names: List[str]) -> Dict[str, Dict]:
    """批量加载表结构"""
    tasks = []
    
    for table_name in table_names:
        task = asyncio.create_task(self.db_access.get_table_schema(table_name))
        tasks.append((table_name, task))
    
    results = {}
    for table_name, task in tasks:
        try:
            schema = await task
            results[table_name] = schema
        except Exception as e:
            logger.error(f"加载表 {table_name} 结构失败: {e}")
    
    return results
```

## 监控和日志

### 性能监控

```python
from prometheus_client import Counter, Histogram, Gauge

# 定义监控指标
schema_search_requests = Counter('schema_search_requests_total', 
                                'Total schema search requests')
schema_search_duration = Histogram('schema_search_duration_seconds',
                                  'Schema search duration')
schema_cache_hits = Counter('schema_cache_hits_total',
                           'Schema cache hits')
schema_cache_misses = Counter('schema_cache_misses_total',
                             'Schema cache misses')
vector_index_size = Gauge('vector_index_size',
                         'Number of schemas in vector index')

class MonitoredSchemaRetrievalService(SchemaRetrievalService):
    async def get_relevant_schemas(self, query: str, max_tables: int = 10):
        schema_search_requests.inc()
        
        start_time = time.time()
        try:
            result = await super().get_relevant_schemas(query, max_tables)
            return result
        finally:
            schema_search_duration.observe(time.time() - start_time)
            vector_index_size.set(len(self.schema_cache))
```

## 测试用例

### 单元测试

```python
import pytest
from unittest.mock import AsyncMock, MagicMock

class TestSchemaRetrievalService:
    @pytest.fixture
    def mock_db_access(self):
        db_access = AsyncMock(spec=DBAccess)
        db_access.get_all_tables.return_value = ['users', 'orders', 'products']
        db_access.get_table_schema.return_value = {
            'table_name': 'users',
            'table_comment': '用户表',
            'columns': [
                {
                    'column_name': 'id',
                    'data_type': 'int',
                    'is_nullable': 'NO',
                    'column_key': 'PRI',
                    'column_comment': '用户ID'
                }
            ]
        }
        return db_access
    
    @pytest.fixture
    async def service(self, mock_db_access):
        service = SchemaRetrievalService(mock_db_access)
        await service.initialize()
        return service
    
    @pytest.mark.asyncio
    async def test_get_relevant_schemas(self, service):
        """测试获取相关模式"""
        schemas = await service.get_relevant_schemas("查找用户信息")
        
        assert len(schemas) > 0
        assert any(schema['table_name'] == 'users' for schema in schemas)
    
    @pytest.mark.asyncio
    async def test_build_context(self, service):
        """测试构建上下文"""
        context = await service.build_context("用户订单统计")
        
        assert isinstance(context, str)
        assert len(context) > 0
        assert 'users' in context or 'orders' in context
```

---

*此文档提供了数据库模式检索服务的完整实现指南，包括多数据库支持、向量化检索、缓存优化和监控机制。*